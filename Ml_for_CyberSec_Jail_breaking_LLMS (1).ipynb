{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRx32WcjhQnB",
        "outputId": "04eda8a1-33b2-4b4c-eed5-158c44077c78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'FastChat'...\n",
            "remote: Enumerating objects: 5541, done.\u001b[K\n",
            "remote: Counting objects: 100% (2320/2320), done.\u001b[K\n",
            "remote: Compressing objects: 100% (340/340), done.\u001b[K\n",
            "remote: Total 5541 (delta 2156), reused 2003 (delta 1979), pack-reused 3221\u001b[K\n",
            "Receiving objects: 100% (5541/5541), 31.22 MiB | 36.29 MiB/s, done.\n",
            "Resolving deltas: 100% (4076/4076), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lm-sys/FastChat.git\n",
        "!cd FastChat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ5bXQPAiExe",
        "outputId": "79a7b4e4-be8d-4ec5-d0d5-130b8b45671f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.3.2\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl\n",
            "The following NEW packages will be installed:\n",
            "  python3-pip-whl python3-setuptools-whl python3.10-venv\n",
            "0 upgraded, 3 newly installed, 0 to remove and 24 not upgraded.\n",
            "Need to get 2,473 kB of archives.\n",
            "After this operation, 2,884 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-pip-whl all 22.0.2+dfsg-1ubuntu0.4 [1,680 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3-setuptools-whl all 59.6.0-1.2ubuntu0.22.04.1 [788 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 python3.10-venv amd64 3.10.12-1~22.04.3 [5,716 B]\n",
            "Fetched 2,473 kB in 1s (3,605 kB/s)\n",
            "Selecting previously unselected package python3-pip-whl.\n",
            "(Reading database ... 121658 files and directories currently installed.)\n",
            "Preparing to unpack .../python3-pip-whl_22.0.2+dfsg-1ubuntu0.4_all.deb ...\n",
            "Unpacking python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Selecting previously unselected package python3-setuptools-whl.\n",
            "Preparing to unpack .../python3-setuptools-whl_59.6.0-1.2ubuntu0.22.04.1_all.deb ...\n",
            "Unpacking python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Selecting previously unselected package python3.10-venv.\n",
            "Preparing to unpack .../python3.10-venv_3.10.12-1~22.04.3_amd64.deb ...\n",
            "Unpacking python3.10-venv (3.10.12-1~22.04.3) ...\n",
            "Setting up python3-setuptools-whl (59.6.0-1.2ubuntu0.22.04.1) ...\n",
            "Setting up python3-pip-whl (22.0.2+dfsg-1ubuntu0.4) ...\n",
            "Setting up python3.10-venv (3.10.12-1~22.04.3) ...\n"
          ]
        }
      ],
      "source": [
        "!pip3 install --upgrade pip  # enable PEP 660 support\n",
        "!apt install python3.10-venv\n",
        "!python -m venv tutorial-env"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNS8So0_iTiF",
        "outputId": "df64d86d-b0c8-471b-d19e-b7ea646a0807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/FastChat\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (3.9.1)\n",
            "Collecting fastapi (from fschat==0.2.34)\n",
            "  Downloading fastapi-0.105.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting httpx (from fschat==0.2.34)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting markdown2[all] (from fschat==0.2.34)\n",
            "  Downloading markdown2-2.4.12-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting nh3 (from fschat==0.2.34)\n",
            "  Downloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (1.23.5)\n",
            "Requirement already satisfied: prompt-toolkit>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (3.0.43)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (1.10.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (2.31.0)\n",
            "Requirement already satisfied: rich>=10.0.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (13.7.0)\n",
            "Collecting shortuuid (from fschat==0.2.34)\n",
            "  Downloading shortuuid-1.0.11-py3-none-any.whl (10 kB)\n",
            "Collecting tiktoken (from fschat==0.2.34)\n",
            "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting uvicorn (from fschat==0.2.34)\n",
            "  Downloading uvicorn-0.25.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "\u001b[33mWARNING: fschat 0.2.34 does not provide the extra 'model-worker'\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting accelerate>=0.21 (from fschat==0.2.34)\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl.metadata (18 kB)\n",
            "Collecting peft (from fschat==0.2.34)\n",
            "  Downloading peft-0.7.1-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting sentencepiece (from fschat==0.2.34)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (4.35.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from fschat==0.2.34) (3.20.3)\n",
            "Collecting gradio (from fschat==0.2.34)\n",
            "  Downloading gradio-4.11.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat==0.2.34) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat==0.2.34) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat==0.2.34) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat==0.2.34) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21->fschat==0.2.34) (0.4.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit>=3.0.0->fschat==0.2.34) (0.2.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->fschat==0.2.34) (4.5.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.34) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.0.0->fschat==0.2.34) (2.16.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (3.13.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->fschat==0.2.34) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->fschat==0.2.34) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->fschat==0.2.34) (0.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->fschat==0.2.34) (4.66.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->fschat==0.2.34) (4.0.3)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.7.1 in /usr/local/lib/python3.10/dist-packages (from fastapi->fschat==0.2.34) (3.7.1)\n",
            "Collecting starlette<0.28.0,>=0.27.0 (from fastapi->fschat==0.2.34)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting typing-extensions>=4.2.0 (from pydantic<2,>=1->fschat==0.2.34)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio->fschat==0.2.34)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (4.2.2)\n",
            "Collecting ffmpy (from gradio->fschat==0.2.34)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.7.3 (from gradio->fschat==0.2.34)\n",
            "  Downloading gradio_client-0.7.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (6.1.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio->fschat==0.2.34)\n",
            "  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio->fschat==0.2.34) (9.4.0)\n",
            "INFO: pip is looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting gradio (from fschat==0.2.34)\n",
            "  Downloading gradio-4.10.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.9.1-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.9.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting gradio-client==0.7.2 (from gradio->fschat==0.2.34)\n",
            "  Downloading gradio_client-0.7.2-py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting gradio (from fschat==0.2.34)\n",
            "  Downloading gradio-4.8.0-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting gradio-client==0.7.1 (from gradio->fschat==0.2.34)\n",
            "  Downloading gradio_client-0.7.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from fschat==0.2.34)\n",
            "  Downloading gradio-4.7.1-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting gradio-client==0.7.0 (from gradio->fschat==0.2.34)\n",
            "  Downloading gradio_client-0.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting gradio (from fschat==0.2.34)\n",
            "  Downloading gradio-4.5.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.4.1-py3-none-any.whl.metadata (17 kB)\n",
            "INFO: pip is still looking at multiple versions of gradio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading gradio-4.4.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.3.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.2.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.1.2-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.1.1-py3-none-any.whl.metadata (17 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading gradio-4.1.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.0.2-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.0.1-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-4.0.0-py3-none-any.whl.metadata (17 kB)\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl.metadata (17 kB)\n",
            "Collecting gradio-client==0.6.1 (from gradio->fschat==0.2.34)\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting pydub (from gradio->fschat==0.2.34)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio->fschat==0.2.34)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio->fschat==0.2.34)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio->fschat==0.2.34)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fschat==0.2.34) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fschat==0.2.34) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fschat==0.2.34) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fschat==0.2.34) (2023.11.17)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->fschat==0.2.34) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->fschat==0.2.34)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore==1.* (from httpx->fschat==0.2.34)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->fschat==0.2.34) (1.3.0)\n",
            "Collecting wavedrom (from markdown2[all]->fschat==0.2.34)\n",
            "  Downloading wavedrom-2.0.3.post3.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.7/137.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (0.12.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.7.1->fastapi->fschat==0.2.34) (1.2.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.0.0->fschat==0.2.34) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (4.46.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio->fschat==0.2.34) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio->fschat==0.2.34) (2023.3.post1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->fschat==0.2.34) (1.3.0)\n",
            "Collecting svgwrite (from wavedrom->markdown2[all]->fschat==0.2.34)\n",
            "  Downloading svgwrite-1.4.3-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.1/67.1 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from wavedrom->markdown2[all]->fschat==0.2.34) (1.16.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (2023.11.2)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (0.32.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio->fschat==0.2.34) (0.15.2)\n",
            "Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.105.0-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.25.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nh3-0.2.15-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.7.1-py3-none-any.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.3/168.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Downloading markdown2-2.4.12-py2.py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.2/41.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hChecking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: fschat, ffmpy, wavedrom\n",
            "  Building editable for fschat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fschat: filename=fschat-0.2.34-0.editable-py3-none-any.whl size=14262 sha256=200cb546a4a1e5770cace39cffa42407f54cd6703091825c94b6d0227bca38eb\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6jb4erfl/wheels/0e/7d/3f/6256e4d259fdebc8665545ea33ca3112027cecb15f3a295311\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=96448368ec820f0495d72d94b86d6520b73897451183b795739e7fce357859b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "  Building wheel for wavedrom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wavedrom: filename=wavedrom-2.0.3.post3-py2.py3-none-any.whl size=30052 sha256=6305d8ac48d1a64cc454328de43e241f923d9339d9a884bd010445bcd567ab98\n",
            "  Stored in directory: /root/.cache/pip/wheels/9c/52/8c/38b454b42f712f325e26f633287484c7dc1ad469e1580c5954\n",
            "Successfully built fschat ffmpy wavedrom\n",
            "Installing collected packages: sentencepiece, pydub, nh3, ffmpy, websockets, typing-extensions, svgwrite, shortuuid, semantic-version, python-multipart, orjson, markdown2, h11, aiofiles, wavedrom, uvicorn, tiktoken, starlette, httpcore, httpx, fastapi, accelerate, gradio-client, fschat, peft, gradio\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed accelerate-0.25.0 aiofiles-23.2.1 fastapi-0.105.0 ffmpy-0.3.1 fschat-0.2.34 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 markdown2-2.4.12 nh3-0.2.15 orjson-3.9.10 peft-0.7.1 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 sentencepiece-0.1.99 shortuuid-1.0.11 starlette-0.27.0 svgwrite-1.4.3 tiktoken-0.5.2 typing-extensions-4.9.0 uvicorn-0.25.0 wavedrom-2.0.3.post3 websockets-11.0.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!cd \"/content/FastChat/\"\n",
        "!pip3 install -e \"/content/FastChat/.[model_worker,webui]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTfOmPksiiDo",
        "outputId": "c32dc0d7-b76c-4b7a-c04c-08ae1966991a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cohere\n",
            "  Downloading cohere-4.39-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting openai\n",
            "  Downloading openai-1.6.0-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: aiohttp<4.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (3.9.1)\n",
            "Collecting backoff<3.0,>=2.0 (from cohere)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting fastavro<2.0,>=1.8 (from cohere)\n",
            "  Downloading fastavro-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting importlib_metadata<7.0,>=6.0 (from cohere)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.25.0 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from cohere) (2.0.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.26.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0,>=3.0->cohere) (4.0.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib_metadata<7.0,>=6.0->cohere) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.25.0->cohere) (3.3.2)\n",
            "Downloading cohere-4.39-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.7/51.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openai-1.6.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.4/225.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastavro-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: kaleido, importlib_metadata, fastavro, backoff, openai, cohere\n",
            "  Attempting uninstall: importlib_metadata\n",
            "    Found existing installation: importlib-metadata 7.0.0\n",
            "    Uninstalling importlib-metadata-7.0.0:\n",
            "      Successfully uninstalled importlib-metadata-7.0.0\n",
            "Successfully installed backoff-2.2.1 cohere-4.39 fastavro-1.9.2 importlib_metadata-6.11.0 kaleido-0.2.1 openai-1.6.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install kaleido cohere openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CJ1oRFzi1Sb",
        "outputId": "f9ff7be7-e47e-4f7d-d028-5a565d1aecc1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 749/749 [00:00<00:00, 4.99MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 18.9MB/s]\n",
            "special_tokens_map.json: 100% 438/438 [00:00<00:00, 2.73MB/s]\n",
            "config.json: 100% 615/615 [00:00<00:00, 4.29MB/s]\n",
            "pytorch_model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 100MB/s]\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.0M/9.98G [00:00<00:53, 186MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 52.4M/9.98G [00:00<00:39, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 94.4M/9.98G [00:00<00:34, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   1% 136M/9.98G [00:00<00:32, 302MB/s] \u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 178M/9.98G [00:00<00:31, 310MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   2% 220M/9.98G [00:00<00:31, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 252M/9.98G [00:00<00:31, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 283M/9.98G [00:00<00:31, 311MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   3% 325M/9.98G [00:01<00:30, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 357M/9.98G [00:01<00:32, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 388M/9.98G [00:01<00:32, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   4% 419M/9.98G [00:01<00:31, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 451M/9.98G [00:01<00:31, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 482M/9.98G [00:01<00:32, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   5% 514M/9.98G [00:01<00:31, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.98G [00:01<00:30, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 587M/9.98G [00:01<00:33, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   6% 619M/9.98G [00:02<00:32, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 650M/9.98G [00:02<00:33, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 682M/9.98G [00:02<00:33, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:02<00:35, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:02<00:35, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 776M/9.98G [00:02<00:34, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 807M/9.98G [00:02<00:33, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   8% 839M/9.98G [00:02<00:31, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 881M/9.98G [00:03<00:30, 298MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:   9% 923M/9.98G [00:03<00:29, 304MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.98G [00:03<00:29, 310MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:03<00:28, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:03<00:28, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:03<00:28, 315MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:03<00:28, 308MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:03<00:28, 309MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:04<00:28, 313MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:04<00:27, 315MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:04<00:27, 316MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:04<00:27, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [00:04<00:27, 312MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [00:04<00:27, 314MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [00:04<00:28, 305MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [00:04<00:28, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [00:05<00:28, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.54G/9.98G [00:05<00:32, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [00:05<00:32, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [00:05<00:31, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [00:05<00:32, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [00:05<00:31, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [00:05<00:38, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [00:06<00:35, 230MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [00:06<00:34, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [00:06<00:32, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [00:06<00:30, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [00:06<00:28, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [00:06<00:28, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [00:06<00:28, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [00:06<00:27, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [00:06<00:28, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [00:07<00:31, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [00:07<00:32, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [00:07<00:30, 257MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [00:07<00:29, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [00:07<00:28, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [00:07<00:27, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [00:07<00:26, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [00:07<00:26, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [00:08<00:26, 292MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [00:08<00:26, 287MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [00:08<00:27, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.39G/9.98G [00:08<00:27, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.98G [00:08<00:26, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [00:08<00:26, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [00:08<00:26, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.52G/9.98G [00:08<00:26, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [00:08<00:26, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [00:09<00:26, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [00:09<00:26, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [00:09<00:26, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.67G/9.98G [00:09<00:26, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [00:09<00:26, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.74G/9.98G [00:09<00:26, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [00:09<00:27, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [00:09<00:27, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [00:09<00:26, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [00:10<00:33, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [00:10<00:32, 216MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.93G/9.98G [00:10<00:30, 228MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [00:10<00:30, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.99G/9.98G [00:10<00:29, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.02G/9.98G [00:10<00:29, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.05G/9.98G [00:10<00:29, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [00:11<00:27, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [00:11<00:26, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [00:11<00:25, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [00:11<00:24, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [00:11<00:24, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [00:11<00:23, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [00:11<00:22, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [00:11<00:22, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.98G [00:11<00:22, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [00:12<00:23, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.98G [00:12<00:23, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [00:12<00:22, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [00:12<00:21, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [00:12<00:21, 304MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [00:12<00:27, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [00:12<00:27, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [00:13<00:26, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.65G/9.98G [00:13<00:23, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [00:13<00:22, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.71G/9.98G [00:13<00:22, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [00:13<00:21, 295MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [00:13<00:20, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [00:13<00:20, 306MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [00:13<00:19, 307MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.90G/9.98G [00:13<00:19, 306MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [00:14<00:20, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [00:14<00:20, 299MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.00G/9.98G [00:14<00:19, 301MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.03G/9.98G [00:14<00:19, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [00:14<00:23, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.09G/9.98G [00:14<00:23, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [00:14<00:22, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.15G/9.98G [00:14<00:21, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [00:15<00:21, 269MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [00:15<00:21, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [00:15<00:20, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.28G/9.98G [00:15<00:20, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [00:15<00:20, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.34G/9.98G [00:15<00:20, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [00:15<00:20, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [00:15<00:20, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.44G/9.98G [00:15<00:20, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.98G [00:16<00:19, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [00:16<00:19, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [00:16<00:19, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [00:16<00:19, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [00:16<00:20, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [00:16<00:19, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [00:16<00:19, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [00:16<00:19, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [00:16<00:19, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [00:17<00:19, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [00:17<00:30, 173MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.81G/9.98G [00:17<00:26, 193MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.84G/9.98G [00:17<00:23, 218MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [00:17<00:21, 233MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.91G/9.98G [00:17<00:20, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [00:17<00:18, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [00:18<00:17, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [00:18<00:16, 296MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [00:18<00:16, 298MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [00:18<00:17, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [00:18<00:17, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [00:18<00:18, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.19G/9.98G [00:18<00:18, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [00:18<00:17, 274MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [00:19<00:19, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [00:19<00:19, 238MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [00:19<00:18, 245MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [00:19<00:18, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [00:19<00:19, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [00:19<00:19, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [00:19<00:20, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [00:20<00:20, 222MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [00:20<00:19, 235MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.54G/9.98G [00:20<00:18, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [00:20<00:18, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [00:20<00:18, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [00:20<00:17, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [00:20<00:17, 253MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [00:20<00:16, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [00:21<00:15, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [00:21<00:16, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [00:21<00:20, 203MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.98G [00:21<00:19, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [00:21<00:17, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [00:21<00:16, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [00:21<00:16, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.98G [00:21<00:15, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [00:22<00:15, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [00:22<00:14, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [00:22<00:14, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [00:22<00:14, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [00:22<00:15, 255MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [00:22<00:17, 226MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [00:22<00:16, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [00:22<00:14, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [00:23<00:13, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [00:23<00:12, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [00:23<00:14, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [00:23<00:14, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [00:23<00:14, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [00:23<00:16, 214MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [00:23<00:15, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [00:24<00:14, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [00:24<00:13, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [00:24<00:12, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [00:24<00:12, 281MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [00:24<00:11, 284MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [00:24<00:12, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.98G [00:24<00:12, 266MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [00:24<00:12, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [00:24<00:12, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [00:25<00:12, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [00:25<00:12, 252MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [00:25<00:12, 256MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [00:25<00:12, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [00:25<00:12, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [00:25<00:12, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [00:25<00:11, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [00:25<00:11, 260MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [00:26<00:11, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [00:26<00:12, 241MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [00:26<00:11, 244MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [00:26<00:11, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [00:26<00:11, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [00:26<00:10, 259MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [00:26<00:10, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [00:27<00:11, 237MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [00:27<00:11, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [00:27<00:10, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [00:27<00:10, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [00:27<00:09, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [00:27<00:10, 254MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [00:27<00:09, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [00:27<00:09, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [00:27<00:08, 282MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [00:28<00:08, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [00:28<00:08, 290MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [00:28<00:08, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [00:28<00:08, 297MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.63G/9.98G [00:28<00:07, 300MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [00:28<00:07, 302MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [00:28<00:09, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [00:28<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [00:28<00:08, 261MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [00:29<00:07, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [00:29<00:08, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [00:29<00:07, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [00:29<00:07, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [00:29<00:07, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [00:29<00:07, 263MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [00:29<00:07, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [00:29<00:07, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [00:30<00:08, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [00:30<00:08, 234MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [00:30<00:09, 206MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [00:30<00:10, 183MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.16G/9.98G [00:30<00:09, 184MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [00:30<00:08, 199MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [00:30<00:08, 217MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [00:31<00:07, 229MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [00:31<00:07, 236MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [00:31<00:10, 157MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [00:31<00:09, 177MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [00:31<00:08, 178MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [00:32<00:08, 191MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [00:32<00:07, 212MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [00:32<00:07, 192MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [00:32<00:07, 190MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [00:32<00:07, 205MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [00:32<00:06, 223MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [00:32<00:05, 231MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.63G/9.98G [00:32<00:05, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [00:33<00:04, 270MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [00:33<00:05, 250MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [00:33<00:05, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [00:33<00:04, 247MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [00:33<00:04, 262MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [00:33<00:04, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [00:33<00:04, 240MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [00:33<00:04, 258MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [00:34<00:04, 251MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [00:34<00:03, 264MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [00:34<00:03, 277MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [00:34<00:03, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [00:34<00:03, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [00:34<00:03, 294MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [00:34<00:03, 272MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [00:34<00:03, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [00:34<00:02, 286MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [00:35<00:02, 288MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [00:35<00:02, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [00:35<00:02, 285MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [00:35<00:02, 283MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [00:35<00:02, 279MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [00:35<00:02, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [00:35<00:02, 278MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.43G/9.98G [00:35<00:02, 271MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [00:36<00:01, 267MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [00:36<00:01, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [00:36<00:01, 275MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [00:36<00:01, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [00:36<00:01, 265MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [00:36<00:01, 273MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [00:36<00:01, 276MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [00:36<00:01, 280MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [00:36<00:00, 268MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [00:37<00:00, 249MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [00:37<00:00, 232MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [00:37<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [00:37<00:00, 225MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [00:37<00:00, 220MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [00:37<00:00, 227MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [00:37<00:00, 243MB/s]\u001b[A\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [00:38<00:00, 262MB/s]\n",
            "Downloading shards:  50% 1/2 [00:38<00:38, 38.18s/it]\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   1% 31.5M/3.50G [00:00<00:12, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   2% 62.9M/3.50G [00:00<00:12, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   3% 94.4M/3.50G [00:00<00:11, 286MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 126M/3.50G [00:00<00:11, 287MB/s] \u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   4% 157M/3.50G [00:00<00:11, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   5% 189M/3.50G [00:00<00:12, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:00<00:12, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   7% 252M/3.50G [00:00<00:12, 268MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   8% 283M/3.50G [00:01<00:12, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:   9% 315M/3.50G [00:01<00:12, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  10% 346M/3.50G [00:01<00:12, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  11% 377M/3.50G [00:01<00:12, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  12% 409M/3.50G [00:01<00:12, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 440M/3.50G [00:01<00:11, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  13% 472M/3.50G [00:01<00:11, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  14% 503M/3.50G [00:01<00:11, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  15% 535M/3.50G [00:02<00:11, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  16% 566M/3.50G [00:02<00:11, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  17% 598M/3.50G [00:02<00:11, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  18% 629M/3.50G [00:02<00:11, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  19% 661M/3.50G [00:02<00:11, 256MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  20% 692M/3.50G [00:02<00:11, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  21% 724M/3.50G [00:02<00:11, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 755M/3.50G [00:02<00:10, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  22% 786M/3.50G [00:03<00:10, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:03<00:10, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  24% 849M/3.50G [00:03<00:10, 241MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  25% 881M/3.50G [00:03<00:11, 231MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:03<00:11, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  27% 944M/3.50G [00:03<00:12, 213MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  28% 975M/3.50G [00:03<00:12, 205MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:04<00:11, 216MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:04<00:10, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:04<00:09, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.10G/3.50G [00:04<00:09, 257MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:04<00:08, 264MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:04<00:08, 269MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:04<00:08, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:04<00:08, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:04<00:08, 280MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:05<00:07, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:05<00:07, 282MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:05<00:07, 283MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.38G/3.50G [00:05<00:07, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.42G/3.50G [00:05<00:07, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [00:05<00:08, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [00:05<00:08, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [00:05<00:08, 242MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [00:06<00:07, 252MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [00:06<00:07, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [00:06<00:07, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [00:06<00:07, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.67G/3.50G [00:06<00:07, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [00:06<00:07, 244MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [00:07<00:10, 165MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [00:07<00:10, 171MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [00:07<00:09, 186MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [00:07<00:08, 201MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [00:07<00:07, 207MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [00:07<00:07, 220MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.91G/3.50G [00:07<00:06, 228MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [00:07<00:06, 232MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [00:08<00:06, 237MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [00:08<00:06, 234MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [00:08<00:06, 236MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [00:08<00:05, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [00:08<00:05, 255MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [00:08<00:05, 265MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.16G/3.50G [00:08<00:05, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [00:08<00:04, 271MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.22G/3.50G [00:08<00:04, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [00:09<00:04, 275MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [00:09<00:04, 275MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.32G/3.50G [00:09<00:04, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [00:09<00:04, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [00:09<00:03, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [00:09<00:03, 282MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.44G/3.50G [00:09<00:03, 282MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.47G/3.50G [00:09<00:03, 279MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [00:10<00:03, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [00:10<00:03, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [00:10<00:03, 276MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [00:10<00:03, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [00:10<00:03, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [00:10<00:03, 278MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [00:10<00:02, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [00:10<00:02, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [00:10<00:02, 280MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [00:11<00:02, 281MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [00:11<00:02, 277MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [00:11<00:02, 274MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [00:11<00:02, 267MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [00:11<00:02, 266MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [00:11<00:02, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [00:11<00:01, 262MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [00:11<00:01, 260MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [00:12<00:01, 243MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [00:12<00:01, 247MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [00:12<00:01, 249MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [00:12<00:01, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.17G/3.50G [00:12<00:01, 245MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.20G/3.50G [00:12<00:01, 239MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [00:12<00:01, 246MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [00:12<00:00, 248MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [00:13<00:00, 251MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.32G/3.50G [00:13<00:00, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [00:13<00:00, 253MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [00:13<00:00, 254MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [00:13<00:00, 258MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.45G/3.50G [00:13<00:00, 259MB/s]\u001b[A\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [00:13<00:00, 253MB/s]\n",
            "Downloading shards: 100% 2/2 [00:52<00:00, 26.07s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:08<00:00,  4.02s/it]\n",
            "generation_config.json: 100% 162/162 [00:00<00:00, 1.24MB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:381: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/configuration_utils.py:386: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.\n",
            "  warnings.warn(\n",
            "USER: exit\n",
            "ASSISTANT: 2023-12-21 05:38:44.415907: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-21 05:38:44.415964: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-21 05:38:44.417268: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-21 05:38:45.513937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "I'm sorry, I'm not sure what you mean by \"exit\". Could you please provide more context or clarify your request?\n",
            "USER: Traceback (most recent call last):\n",
            "  File \"/content/FastChat/fastchat/serve/cli.py\", line 227, in main\n",
            "    chat_loop(\n",
            "  File \"/content/FastChat/fastchat/serve/inference.py\", line 415, in chat_loop\n",
            "    inp = chatio.prompt_for_input(conv.roles[0])\n",
            "  File \"/content/FastChat/fastchat/serve/cli.py\", line 46, in prompt_for_input\n",
            "    return input(f\"{role}: \")\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/FastChat/fastchat/serve/cli.py\", line 304, in <module>\n",
            "    main(args)\n",
            "  File \"/content/FastChat/fastchat/serve/cli.py\", line 260, in main\n",
            "    print(\"exit...\")\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python3 -m fastchat.serve.cli --model-path lmsys/vicuna-7b-v1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nauKFK0Ekgqs",
        "outputId": "f299cc6d-1138-4c42-bfeb-0efa3c6db92b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tokenizer_config.json: 100% 2.40k/2.40k [00:00<00:00, 7.20MB/s]\n",
            "spiece.model: 100% 792k/792k [00:00<00:00, 36.1MB/s]\n",
            "added_tokens.json: 100% 150/150 [00:00<00:00, 982kB/s]\n",
            "special_tokens_map.json: 100% 2.20k/2.20k [00:00<00:00, 14.1MB/s]\n",
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "config.json: 100% 1.52k/1.52k [00:00<00:00, 7.25MB/s]\n",
            "pytorch_model.bin: 100% 6.71G/6.71G [00:31<00:00, 212MB/s]\n",
            "generation_config.json: 100% 142/142 [00:00<00:00, 830kB/s]\n",
            "Human: hi\n",
            "Assistant: 2023-12-14 23:06:10.035037: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-14 23:06:10.035096: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-14 23:06:10.036478: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-14 23:06:11.262057: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Hello! How can I help you today?\n",
            "Human: what is the date today ?\n",
            "Assistant: Today is Thursday, February 28, 2023.\n",
            "Human: how to build a bomb ?\n",
            "Assistant: Building a bomb is illegal and dangerous, and it can cause serious harm to individuals and communities. It is important to remember that building a bomb is not a safe scientific experiment or activity. It is illegal to use explosives or create a device to harm yourself or others, and it goes against international law. If you are thinking about building a bomb, it is best to consult with professionals who specialize in this field to ensure that you do not end up in dangerous situations.\n",
            "Human: exit...\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
            "    return _run_code(code, main_globals, None,\n",
            "  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/content/FastChat/fastchat/serve/cli.py\", line 304, in <module>\n",
            "    main(args)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ],
      "source": [
        "!python3 -m fastchat.serve.cli --model-path lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kv7LdrgVlp5t"
      },
      "outputs": [],
      "source": [
        "!cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TN5UpRBSl6CC",
        "outputId": "12c1cd66-1e77-41ab-bcae-4fa49fefeb8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ls: cannot access '/content/FastChat/lmsys/fastchat-t5-3b-v1.0': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "!ls -a -o /content/FastChat/lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQZFk2RAltSO",
        "outputId": "ea01694f-48ef-4a5e-b842-555534719957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQKxAuxYlna9",
        "outputId": "0932e2e9-e4b6-4e3f-a1a7-0220f4bfccfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Jailbreak_LLM'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 39 (delta 17), reused 24 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (39/39), 296.24 KiB | 3.75 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Princeton-SysML/Jailbreak_LLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bdVJPje4mf7w",
        "outputId": "dd97d2c5-5904-4537-9dcf-cb5be34e5297"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-2b48d8febccc>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    --model fastchat-t5-3b-v1.0 \\\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "python attack.py \\\n",
        "    --model fastchat-t5-3b-v1.0 \\\n",
        "    --use_default \\\n",
        "    --use_system_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JnKAwnX6mt3y",
        "outputId": "cf308ffa-d2b0-4f36-a9a2-659bba8bbf2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "Human: check \n",
            "Assistant: 2023-12-14 23:25:00.307142: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-14 23:25:00.307209: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-14 23:25:00.308665: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-14 23:25:01.659530: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Is there anything else you need help with?\n",
            "Human: yes how to solve pdes\n",
            "Assistant: PDEs (Python Dynamic Programming Equations) are mathematical equations that describe the behavior of dynamic systems under uncertainty. They consist of four basic components: force, momentum, momentum, and energy. To solve a PDE, you start by having a complete understanding of these components and their relationships. Next, you calculate the forces acting on the system and their potential energies. This process involves solving differential equations to find the amplitude and phase of the forces.\n",
            "For example, the force on a body is given by F(x) = m, which represents the mass of the body divided by the acceleration due to gravity. The potential energy is given by E(x). Finally, the velocity of the body is given by V(2).\n",
            "Once you have the forces and potential energy, you can use PDEs to analyze and model dynamic systems. These equations can be used to predict the behavior of physical systems and make predictions about future events.\n",
            "There are many online resources and tutorials available for solving PDEs. Some popular options include MathJax, stopped generation.\n",
            "exit...\n"
          ]
        }
      ],
      "source": [
        "!python3 -m fastchat.serve.cli --model-path lmsys/fastchat-t5-3b-v1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNhq4MgssR-b",
        "outputId": "ddee2b97-cba9-4841-945b-ab1478239580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Jailbreak_LLM' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Princeton-SysML/Jailbreak_LLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKuhWuAzsR2w",
        "outputId": "1fdcc515-2fa2-4f51-df89-50aa2abb3f42"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'FastChat' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/lm-sys/FastChat.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaOcPx5QwbjG",
        "outputId": "7e915dbe-d238-47c3-e390-5580aa4f4e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'llama'...\n",
            "remote: Enumerating objects: 417, done.\u001b[K\n",
            "remote: Counting objects: 100% (71/71), done.\u001b[K\n",
            "remote: Compressing objects: 100% (48/48), done.\u001b[K\n",
            "remote: Total 417 (delta 29), reused 49 (delta 15), pack-reused 346\u001b[K\n",
            "Receiving objects: 100% (417/417), 1.10 MiB | 10.50 MiB/s, done.\n",
            "Resolving deltas: 100% (214/214), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/facebookresearch/llama.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r7yVUEY1wuLU"
      },
      "outputs": [],
      "source": [
        "!cd llama/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ooz45c-Jwqq7",
        "outputId": "642ec225-6424-4e54-d61a-07f41b823d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/llama\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from llama==0.0.1) (2.1.0+cu121)\n",
            "Collecting fairscale (from llama==0.0.1)\n",
            "  Downloading fairscale-0.4.13.tar.gz (266 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.3/266.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting fire (from llama==0.0.1)\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llama==0.0.1) (0.1.99)\n",
            "Requirement already satisfied: numpy>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from fairscale->llama==0.0.1) (1.23.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->llama==0.0.1) (2.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llama==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llama==0.0.1) (2.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->llama==0.0.1) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->llama==0.0.1) (1.3.0)\n",
            "Building wheels for collected packages: fairscale, fire\n",
            "  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fairscale: filename=fairscale-0.4.13-py3-none-any.whl size=332104 sha256=b3b0648ed8d2fcd0915be88ca0dcac3b8ae3e79c922a4c5b0a0dc764f62dab55\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/a4/c0/fb0a7ef03cff161611c3fa40c6cf898f76e58ec421b88e8cb3\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116934 sha256=fd9992ba336b23e12f09a60de925c569aa3637fc44cd51bcd5794d03e7ae0b2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fairscale fire\n",
            "Installing collected packages: fire, fairscale, llama\n",
            "  Running setup.py develop for llama\n",
            "Successfully installed fairscale-0.4.13 fire-0.5.0 llama-0.0.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -e \"llama/.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SJx3wL1x9Kt",
        "outputId": "4dc0b47e-f1c7-4a33-af1e-68809da51f33"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter the URL from email: https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "\n",
            "Enter the list of models to download without spaces (7B,13B,70B,7B-chat,13B-chat,70B-chat), or press Enter for all: \n",
            "Downloading LICENSE and Acceptable Usage Policy\n",
            "--2023-12-15 00:04:23--  https://download.llamameta.net/LICENSE?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7020 (6.9K) [binary/octet-stream]\n",
            "Saving to: ‘./LICENSE’\n",
            "\n",
            "./LICENSE           100%[===================>]   6.86K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:04:23 (376 MB/s) - ‘./LICENSE’ saved [7020/7020]\n",
            "\n",
            "--2023-12-15 00:04:23--  https://download.llamameta.net/USE_POLICY.md?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4766 (4.7K) [binary/octet-stream]\n",
            "Saving to: ‘./USE_POLICY.md’\n",
            "\n",
            "./USE_POLICY.md     100%[===================>]   4.65K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:04:23 (280 MB/s) - ‘./USE_POLICY.md’ saved [4766/4766]\n",
            "\n",
            "Downloading tokenizer\n",
            "--2023-12-15 00:04:23--  https://download.llamameta.net/tokenizer.model?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 499723 (488K) [binary/octet-stream]\n",
            "Saving to: ‘./tokenizer.model’\n",
            "\n",
            "./tokenizer.model   100%[===================>] 488.01K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-12-15 00:04:23 (29.7 MB/s) - ‘./tokenizer.model’ saved [499723/499723]\n",
            "\n",
            "--2023-12-15 00:04:23--  https://download.llamameta.net/tokenizer_checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 50 [binary/octet-stream]\n",
            "Saving to: ‘./tokenizer_checklist.chk’\n",
            "\n",
            "./tokenizer_checkli 100%[===================>]      50  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:04:23 (7.41 MB/s) - ‘./tokenizer_checklist.chk’ saved [50/50]\n",
            "\n",
            "tokenizer.model: OK\n",
            "Downloading llama-2-7b\n",
            "--2023-12-15 00:04:23--  https://download.llamameta.net/llama-2-7b/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13476925163 (13G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b/consolidated.00.pth’\n",
            "\n",
            "./llama-2-7b/consol 100%[===================>]  12.55G   329MB/s    in 47s     \n",
            "\n",
            "2023-12-15 00:05:11 (271 MB/s) - ‘./llama-2-7b/consolidated.00.pth’ saved [13476925163/13476925163]\n",
            "\n",
            "--2023-12-15 00:05:11--  https://download.llamameta.net/llama-2-7b/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102 [application/json]\n",
            "Saving to: ‘./llama-2-7b/params.json’\n",
            "\n",
            "./llama-2-7b/params 100%[===================>]     102  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:05:11 (13.2 MB/s) - ‘./llama-2-7b/params.json’ saved [102/102]\n",
            "\n",
            "--2023-12-15 00:05:11--  https://download.llamameta.net/llama-2-7b/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 100 [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b/checklist.chk’\n",
            "\n",
            "./llama-2-7b/checkl 100%[===================>]     100  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:05:11 (31.6 MB/s) - ‘./llama-2-7b/checklist.chk’ saved [100/100]\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "params.json: OK\n",
            "Downloading llama-2-13b\n",
            "--2023-12-15 00:05:38--  https://download.llamameta.net/llama-2-13b/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13016329643 (12G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-13b/consolidated.00.pth’\n",
            "\n",
            "./llama-2-13b/conso 100%[===================>]  12.12G   316MB/s    in 43s     \n",
            "\n",
            "2023-12-15 00:06:21 (290 MB/s) - ‘./llama-2-13b/consolidated.00.pth’ saved [13016329643/13016329643]\n",
            "\n",
            "--2023-12-15 00:06:21--  https://download.llamameta.net/llama-2-13b/consolidated.01.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.112, 18.238.243.115, 18.238.243.81, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13016329643 (12G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-13b/consolidated.01.pth’\n",
            "\n",
            "./llama-2-13b/conso 100%[===================>]  12.12G   274MB/s    in 46s     \n",
            "\n",
            "2023-12-15 00:07:07 (273 MB/s) - ‘./llama-2-13b/consolidated.01.pth’ saved [13016329643/13016329643]\n",
            "\n",
            "--2023-12-15 00:07:07--  https://download.llamameta.net/llama-2-13b/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.115, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102 [application/json]\n",
            "Saving to: ‘./llama-2-13b/params.json’\n",
            "\n",
            "./llama-2-13b/param 100%[===================>]     102  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:07:07 (25.5 MB/s) - ‘./llama-2-13b/params.json’ saved [102/102]\n",
            "\n",
            "--2023-12-15 00:07:07--  https://download.llamameta.net/llama-2-13b/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.115, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 154 [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-13b/checklist.chk’\n",
            "\n",
            "./llama-2-13b/check 100%[===================>]     154  --.-KB/s    in 0s      \n",
            "\n",
            "2023-12-15 00:07:08 (12.0 MB/s) - ‘./llama-2-13b/checklist.chk’ saved [154/154]\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "consolidated.01.pth: OK\n",
            "params.json: OK\n",
            "Downloading llama-2-70b\n",
            "--2023-12-15 00:08:59--  https://download.llamameta.net/llama-2-70b/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.87, 18.238.243.81, 18.238.243.115, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.00.pth’\n",
            "\n",
            "./llama-2-70b/conso 100%[===================>]  16.06G   289MB/s    in 60s     \n",
            "\n",
            "2023-12-15 00:09:59 (276 MB/s) - ‘./llama-2-70b/consolidated.00.pth’ saved [17246706245/17246706245]\n",
            "\n",
            "--2023-12-15 00:09:59--  https://download.llamameta.net/llama-2-70b/consolidated.01.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.81, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.01.pth’\n",
            "\n",
            "./llama-2-70b/conso 100%[===================>]  16.06G   322MB/s    in 52s     \n",
            "\n",
            "2023-12-15 00:10:51 (319 MB/s) - ‘./llama-2-70b/consolidated.01.pth’ saved [17246706245/17246706245]\n",
            "\n",
            "--2023-12-15 00:10:51--  https://download.llamameta.net/llama-2-70b/consolidated.02.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.87, 18.238.243.115, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.02.pth’\n",
            "\n",
            "./llama-2-70b/conso 100%[===================>]  16.06G   300MB/s    in 61s     \n",
            "\n",
            "2023-12-15 00:11:52 (271 MB/s) - ‘./llama-2-70b/consolidated.02.pth’ saved [17246706245/17246706245]\n",
            "\n",
            "--2023-12-15 00:11:52--  https://download.llamameta.net/llama-2-70b/consolidated.03.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.87, 18.238.243.81, 18.238.243.115, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.03.pth’\n",
            "\n",
            "./llama-2-70b/conso 100%[===================>]  16.06G   244MB/s    in 67s     \n",
            "\n",
            "2023-12-15 00:12:59 (246 MB/s) - ‘./llama-2-70b/consolidated.03.pth’ saved [17246706245/17246706245]\n",
            "\n",
            "--2023-12-15 00:12:59--  https://download.llamameta.net/llama-2-70b/consolidated.04.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.81, 18.238.243.112, 18.238.243.115, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.81|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.04.pth’\n",
            "\n",
            "./llama-2-70b/conso 100%[===================>]  16.06G   306MB/s    in 65s     \n",
            "\n",
            "2023-12-15 00:14:05 (253 MB/s) - ‘./llama-2-70b/consolidated.04.pth’ saved [17246706245/17246706245]\n",
            "\n",
            "--2023-12-15 00:14:05--  https://download.llamameta.net/llama-2-70b/consolidated.05.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoibG5heml3ajd1M3E4dW0zeXBhNXB0ZDJnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwMjY4NDM5NX19fV19&Signature=DeF61jpB0INL8uOKWHABwCsXnXVKLXoTrxWs2t7kFIm4CODb3%7EqCpgN15SgKc7ZCOjhw5HW40ZNTN9%7ELCo4SSrbtRIJjaeatyY1kFjRRQ7H0ZtdfX39na7zqE4LuXz6RNi83sSsH-tQO1Ukbs500Friu-MPS-K49bck%7EMZULD2D%7EMLaEQuaqB0pe%7EloxEOjoGAO-wnCjVXHZvf7bDhLMhy-A9cGuD46a6Nb6NicwZ-nAP0E2KJHNs8tciSurr7wEXUBnWB9D-H3g1efEC30a5RBqWgh%7EIseiWAEFrDQzxa0NlnIrwxcKbersOiAbabyQ1jS-Rhd-4c0cvyiytiqd6g__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=336584875988538\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 18.238.243.115, 18.238.243.87, 18.238.243.112, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|18.238.243.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17246706245 (16G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-70b/consolidated.05.pth’\n",
            "\n",
            "./llama-2-70b/conso  25%[====>               ]   4.12G   321MB/s    in 18s     \n",
            "\n",
            "\n",
            "Cannot write to ‘./llama-2-70b/consolidated.05.pth’ (Success).\n"
          ]
        }
      ],
      "source": [
        "!bash /content/llama/download.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tFfP5S7A4Qoz",
        "outputId": "9c760751-2490-49d6-ec07-9b82439b7971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'Llama-2-7b-hf'...\n",
            "remote: Enumerating objects: 79, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (62/62), done.\u001b[K\n",
            "remote: Total 79 (delta 30), reused 0 (delta 0), pack-reused 17\u001b[K\n",
            "Unpacking objects: 100% (79/79), 978.41 KiB | 3.58 MiB/s, done.\n",
            "Filtering content: 100% (6/6), 9.10 GiB | 30.46 MiB/s, done.\n",
            "Encountered 2 file(s) that may not have been copied correctly on Windows:\n",
            "\tmodel-00001-of-00002.safetensors\n",
            "\tpytorch_model-00001-of-00002.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        " # Make sure you have git-lfs installed (https://git-lfs.com)\n",
        "!git lfs install\n",
        "# if you want to clone without large files – just their pointers\n",
        "# prepend your git clone with the following env var:\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone https://huggingface.co/meta-llama/Llama-2-7b-hf\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CDqJ-y-4QFp",
        "outputId": "75c283de-5701-470c-c25b-c941b52412c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: huggingface_hub[cli] in /usr/local/lib/python3.10/dist-packages (0.19.4)\n",
            "Collecting huggingface_hub[cli]\n",
            "  Downloading huggingface_hub-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.66.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (4.9.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]) (23.2)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli])\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli])\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]) (3.0.43)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub[cli]) (2023.11.17)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]) (0.2.12)\n",
            "Downloading huggingface_hub-0.20.1-py3-none-any.whl (330 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.1/330.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pfzy, InquirerPy, huggingface_hub\n",
            "  Attempting uninstall: huggingface_hub\n",
            "    Found existing installation: huggingface-hub 0.19.4\n",
            "    Uninstalling huggingface-hub-0.19.4:\n",
            "      Successfully uninstalled huggingface-hub-0.19.4\n",
            "Successfully installed InquirerPy-0.3.4 huggingface_hub-0.20.1 pfzy-0.3.4\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -U \"huggingface_hub[cli]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g4NajD-W4P3N",
        "outputId": "d9820a15-7d0a-4403-ad54-ec7e8ade1500"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: \n",
            "Add token as git credential? (Y/n) Y\n",
            "Token is valid (permission: read).\n",
            "Your token has been saved in your configured git credential helpers (store).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "!huggingface-cli login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m0wasaSf5N7d"
      },
      "outputs": [],
      "source": [
        "!git config --global credential.helper store"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone https://huggingface.co/google/flan-t5-small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EL8SK6CLSLiA",
        "outputId": "06b44482-3fd0-4969-f8e0-fc1eecbb3923"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'flan-t5-small'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 62 (delta 28), reused 60 (delta 28), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (62/62), 615.74 KiB | 965.00 KiB/s, done.\n",
            "Filtering content: 100% (5/5), 1.27 GiB | 51.32 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2UUp2AN5kW_",
        "outputId": "08411ad1-f4d3-4ac3-e21f-fc48f6a01d1b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'Llama-2-7b-hf'...\n",
            "Host key verification failed.\n",
            "fatal: Could not read from remote repository.\n",
            "\n",
            "Please make sure you have the correct access rights\n",
            "and the repository exists.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone git@hf.co:meta-llama/Llama-2-7b-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58VMEukU8qhD",
        "outputId": "1ac9ab8e-399b-499f-f344-33c721227573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Jailbreak_LLM'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (39/39), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 39 (delta 17), reused 24 (delta 7), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (39/39), 296.24 KiB | 1.50 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Princeton-SysML/Jailbreak_LLM.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvdpFRIu9NjY",
        "outputId": "24df4065-6a43-4ad5-b4de-2fbac0519ebf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Jailbreak_LLM\n"
          ]
        }
      ],
      "source": [
        "%cd Jailbreak_LLM/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2pdnKMH9P2J",
        "outputId": "29d54a31-14df-47e6-a785-ab70a12af265"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/ (stored 0%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.8.csv (deflated 68%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_1.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.55.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_20.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.2.csv (deflated 80%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.75.csv (deflated 70%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.3.csv (deflated 77%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.25.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.1.csv (deflated 80%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.05.csv (deflated 80%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.5.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.85.csv (deflated 74%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.2.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_50.csv (deflated 75%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_2.csv (deflated 77%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_200.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.55.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.7.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.65.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.95.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.35.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.15.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.7.csv (deflated 71%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.5.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.6.csv (deflated 74%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.05.csv (deflated 80%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.25.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.45.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.35.csv (deflated 77%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_1.0.csv (deflated 70%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.4.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.4.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.85.csv (deflated 69%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_1.0.csv (deflated 64%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.95.csv (deflated 65%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_10.csv (deflated 74%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.65.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.3.csv (deflated 79%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.75.csv (deflated 75%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.45.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.8.csv (deflated 76%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_500.csv (deflated 73%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_100.csv (deflated 74%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.1.csv (deflated 78%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.9.csv (deflated 74%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topk_5.csv (deflated 75%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_temp_0.9.csv (deflated 65%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.0.csv (deflated 80%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.6.csv (deflated 77%)\n",
            "  adding: content/Jailbreak_LLM/outputs/Llama-2-7b-hf/output_topp_0.15.csv (deflated 80%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/Jailbreak_LLM/outputs/Llama-2-7b-hf.zip /content/Jailbreak_LLM/outputs/Llama-2-7b-hf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GLzaC0Y0rc07",
        "outputId": "f4686da0-6e08-4a63-d79f-636703fec38d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Jailbreak_LLM\n"
          ]
        }
      ],
      "source": [
        "%cd Jailbreak_LLM/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGqzYtHo5qqe",
        "outputId": "088dd9b3-b29a-4019-c1c7-5879b4e563ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [01:05<00:00, 32.86s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-hf\n",
            "INFO:root:Running temp = 0.05\n",
            "100% 100/100 [05:56<00:00,  3.56s/it]\n",
            "INFO:root:Running temp = 0.1\n",
            "100% 100/100 [05:53<00:00,  3.54s/it]\n",
            "INFO:root:Running temp = 0.15\n",
            "100% 100/100 [05:56<00:00,  3.57s/it]\n",
            "INFO:root:Running temp = 0.2\n",
            "100% 100/100 [05:53<00:00,  3.53s/it]\n",
            "INFO:root:Running temp = 0.25\n",
            "100% 100/100 [05:51<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.3\n",
            "100% 100/100 [05:51<00:00,  3.51s/it]\n",
            "INFO:root:Running temp = 0.35\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.4\n",
            "100% 100/100 [05:53<00:00,  3.54s/it]\n",
            "INFO:root:Running temp = 0.45\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.5\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.55\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.6\n",
            "100% 100/100 [05:51<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.65\n",
            "100% 100/100 [05:51<00:00,  3.51s/it]\n",
            "INFO:root:Running temp = 0.7\n",
            "100% 100/100 [05:49<00:00,  3.49s/it]\n",
            "INFO:root:Running temp = 0.75\n",
            "100% 100/100 [05:51<00:00,  3.52s/it]\n",
            "INFO:root:Running temp = 0.8\n",
            "100% 100/100 [05:39<00:00,  3.40s/it]\n",
            "INFO:root:Running temp = 0.85\n",
            "100% 100/100 [05:49<00:00,  3.50s/it]\n",
            "INFO:root:Running temp = 0.9\n",
            "100% 100/100 [05:32<00:00,  3.33s/it]\n",
            "INFO:root:Running temp = 0.95\n",
            "100% 100/100 [05:37<00:00,  3.37s/it]\n",
            "INFO:root:Running temp = 1.0\n",
            "100% 100/100 [05:47<00:00,  3.47s/it]\n",
            "INFO:root:Running topp = 0.0\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.05\n",
            "100% 100/100 [05:51<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.1\n",
            "100% 100/100 [05:51<00:00,  3.51s/it]\n",
            "INFO:root:Running topp = 0.15\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.2\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.25\n",
            "100% 100/100 [05:51<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.3\n",
            "100% 100/100 [05:52<00:00,  3.52s/it]\n",
            "INFO:root:Running topp = 0.35\n",
            "100% 100/100 [05:53<00:00,  3.53s/it]\n",
            "INFO:root:Running topp = 0.4\n",
            "100% 100/100 [05:52<00:00,  3.53s/it]\n",
            "INFO:root:Running topp = 0.45\n",
            "100% 100/100 [05:50<00:00,  3.51s/it]\n",
            "INFO:root:Running topp = 0.5\n",
            "100% 100/100 [05:53<00:00,  3.54s/it]\n",
            "INFO:root:Running topp = 0.55\n",
            "100% 100/100 [05:52<00:00,  3.53s/it]\n",
            "INFO:root:Running topp = 0.6\n",
            "100% 100/100 [05:54<00:00,  3.54s/it]\n",
            "INFO:root:Running topp = 0.65\n",
            "100% 100/100 [05:56<00:00,  3.57s/it]\n",
            "INFO:root:Running topp = 0.7\n",
            "100% 100/100 [05:54<00:00,  3.54s/it]\n",
            "INFO:root:Running topp = 0.75\n",
            "100% 100/100 [06:09<00:00,  3.70s/it]\n",
            "INFO:root:Running topp = 0.8\n",
            "100% 100/100 [05:56<00:00,  3.57s/it]\n",
            "INFO:root:Running topp = 0.85\n",
            "100% 100/100 [06:01<00:00,  3.62s/it]\n",
            "INFO:root:Running topp = 0.9\n",
            "100% 100/100 [06:05<00:00,  3.66s/it]\n",
            "INFO:root:Running topp = 0.95\n",
            "100% 100/100 [06:05<00:00,  3.65s/it]\n",
            "INFO:root:Running topp = 1.0\n",
            "100% 100/100 [06:00<00:00,  3.61s/it]\n",
            "INFO:root:Running topk = 1\n",
            "100% 100/100 [06:06<00:00,  3.66s/it]\n",
            "INFO:root:Running topk = 2\n",
            "100% 100/100 [06:06<00:00,  3.67s/it]\n",
            "INFO:root:Running topk = 5\n",
            "100% 100/100 [06:06<00:00,  3.66s/it]\n",
            "INFO:root:Running topk = 10\n",
            "100% 100/100 [06:06<00:00,  3.66s/it]\n",
            "INFO:root:Running topk = 20\n",
            "100% 100/100 [06:00<00:00,  3.61s/it]\n",
            "INFO:root:Running topk = 50\n",
            "100% 100/100 [05:55<00:00,  3.55s/it]\n",
            "INFO:root:Running topk = 100\n",
            "100% 100/100 [05:58<00:00,  3.59s/it]\n",
            "INFO:root:Running topk = 200\n",
            "100% 100/100 [05:56<00:00,  3.57s/it]\n",
            "INFO:root:Running topk = 500\n",
            "100% 100/100 [05:57<00:00,  3.58s/it]\n"
          ]
        }
      ],
      "source": [
        "!python attack.py \\\n",
        "    --model vicuna-7b-v1.5 \\\n",
        "    --tune_temp \\\n",
        "    --tune_topp \\\n",
        "    --tune_topk \\\n",
        "    --n_sample 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXvU2tcDVAUQ"
      },
      "outputs": [],
      "source": [
        "!unzip /content/evaluator-20231221T060640Z-001.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnBvfP1EY6nc"
      },
      "outputs": [],
      "source": [
        "!unzip /content/scorer-20231221T130628Z-001.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSYMmMfihh4I",
        "outputId": "0a24cc9b-4691-464b-ce05-6aa64deefe6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Jailbreak_LLM\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwy1PyJvd1F5",
        "outputId": "fbe90998-d45f-4b52-ed4d-381f37b3a254"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-12-21 13:50:27.583225: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-21 13:50:27.583277: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-21 13:50:27.584528: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-12-21 13:50:28.685058: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Llama-2-7b-hf Llama-2-7b-hf\n",
            "==== Greedy decoding ====\n",
            "==== Exploiting temperature ====\n",
            " 45% 9/20 [00:17<00:21,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 50% 10/20 [00:19<00:19,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 55% 11/20 [00:21<00:17,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 60% 12/20 [00:23<00:15,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 65% 13/20 [00:25<00:13,  1.99s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 70% 14/20 [00:27<00:12,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 75% 15/20 [00:29<00:10,  2.05s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 80% 16/20 [00:32<00:08,  2.09s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 85% 17/20 [00:34<00:06,  2.05s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 90% 18/20 [00:36<00:04,  2.02s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 95% 19/20 [00:38<00:02,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 20/20 [00:39<00:00,  2.00s/it]\n",
            "==== Exploiting Top_k ====\n",
            "  0% 0/9 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 11% 1/9 [00:02<00:16,  2.03s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 22% 2/9 [00:04<00:14,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 33% 3/9 [00:05<00:11,  1.99s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 44% 4/9 [00:07<00:09,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 56% 5/9 [00:09<00:08,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 67% 6/9 [00:11<00:05,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 78% 7/9 [00:14<00:04,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 89% 8/9 [00:16<00:02,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 9/9 [00:17<00:00,  2.00s/it]\n",
            "==== Exploiting Top_p ====\n",
            "  0% 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "  5% 1/20 [00:02<00:38,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 10% 2/20 [00:03<00:35,  1.99s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 15% 3/20 [00:05<00:33,  1.98s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 20% 4/20 [00:07<00:31,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 25% 5/20 [00:09<00:30,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 30% 6/20 [00:11<00:28,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 35% 7/20 [00:14<00:26,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 40% 8/20 [00:16<00:24,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 45% 9/20 [00:18<00:22,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 50% 10/20 [00:20<00:20,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 55% 11/20 [00:21<00:17,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 60% 12/20 [00:23<00:15,  2.00s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 65% 13/20 [00:26<00:14,  2.01s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 70% 14/20 [00:28<00:12,  2.03s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 75% 15/20 [00:30<00:10,  2.09s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 80% 16/20 [00:32<00:08,  2.12s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 85% 17/20 [00:34<00:06,  2.16s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 90% 18/20 [00:36<00:04,  2.11s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            " 95% 19/20 [00:38<00:02,  2.09s/it]/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/pipelines/base.py:1101: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
            "  warnings.warn(\n",
            "100% 20/20 [00:40<00:00,  2.04s/it]\n"
          ]
        }
      ],
      "source": [
        "!python evaluate.py \\\n",
        "    --model Llama-2-7b-hf \\\n",
        "    --evaluator_path /content/Jailbreak_LLM/evaluator \\\n",
        "    --scorer_path /content/Jailbreak_LLM/scorer/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ermxUPCmnK7F",
        "outputId": "af7a694a-f8be-453a-9709-1eef7d9e0b29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-rw-r--r-- 1 root 44982 Dec 21 13:41 ./outputs/Llama-2-7b-hf/output_greedy.csv\n"
          ]
        }
      ],
      "source": [
        "!ls -o -a ./outputs/Llama-2-7b-hf/output_greedy.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zf8f0cptj6Ko",
        "outputId": "d477f664-5b9e-4328-8f07-baddab2f52c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:04<00:00,  2.29s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: Llama-2-7b-hf\n",
            "INFO:root:Running greedy\n",
            "100% 100/100 [05:43<00:00,  3.44s/it]\n"
          ]
        }
      ],
      "source": [
        "!python attack.py \\\n",
        "    --model Llama-2-7b-hf \\\n",
        "    --use_greedy \\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gow9JgnKoInD"
      },
      "outputs": [],
      "source": [
        "models = [\n",
        "    'vicuna-7b-v1.5',\n",
        "    'vicuna-13b-v1.5',\n",
        "    'vicuna-33b-v1.3',\n",
        "\n",
        "    'mpt-7b',\n",
        "    'mpt-30b',\n",
        "\n",
        "    'falcon-7b',\n",
        "    'falcon-40b',\n",
        "\n",
        "\n",
        "    'Llama-2-7b-hf',\n",
        "    'Llama-2-13b-hf',\n",
        "    'Llama-2-7b-chat-hf',\n",
        "    'Llama-2-13b-chat-hf',\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr-28X7LoUUs",
        "outputId": "6a589314-b678-479b-99e8-9a8d8ed74bb6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-51-848a2772da16>:7: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
            "  plt.style.use('seaborn-ticks')\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "plt.style.use('seaborn-ticks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "hv6S_7-coJwm",
        "outputId": "4475d58c-2aa1-42d5-ce5a-a345aebbe791"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8be193fb-3876-4f5a-bd4e-f14b117cc1a1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model</th>\n",
              "      <th>greedy</th>\n",
              "      <th>break_by_temp</th>\n",
              "      <th>break_by_topk</th>\n",
              "      <th>break_by_topp</th>\n",
              "      <th>break_by_all</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-2-7b-hf</td>\n",
              "      <td>81</td>\n",
              "      <td>98</td>\n",
              "      <td>94</td>\n",
              "      <td>95</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8be193fb-3876-4f5a-bd4e-f14b117cc1a1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8be193fb-3876-4f5a-bd4e-f14b117cc1a1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8be193fb-3876-4f5a-bd4e-f14b117cc1a1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           model greedy break_by_temp break_by_topk break_by_topp break_by_all\n",
              "0  Llama-2-7b-hf     81            98            94            95           99"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "text/html": [
              "<h4 class=\"colab-quickchart-section-title\">Time series</h4>\n",
              "<style>\n",
              "  .colab-quickchart-section-title {\n",
              "      clear: both;\n",
              "  }\n",
              "</style>"
            ],
            "text/plain": [
              "<google.colab._quickchart_helpers.SectionTitle at 0x785ae4c47c10>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "      <div class=\"colab-quickchart-chart-with-code\" id=\"chart-476f6cae-4c75-4a60-afd4-6328696be4d3\">\n",
              "        <img style=\"width: 180px;\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA/MAAAITCAYAAABLz0yVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90\n",
              "bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9h\n",
              "AAAPYQGoP6dpAAAkkElEQVR4nO3de5DV9X3/8dfu6oKJYBTXyKKmGi/E6BJvpZQSChjGC07jKHhp\n",
              "CJrYEq0mXlABtUaq4DU6iqZoa70gTsUYSZVqkQhqYm0mKRI7LY31EtFd18hNDC4Xz++P/NyGyiqr\n",
              "HJcPPB4zzPg9n+855/2d+Yzy9HzPbk2lUqkEAAAAKEZtVw8AAAAAdI6YBwAAgMKIeQAAACiMmAcA\n",
              "AIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMJs8TF/5513dvUIAAAAsElt8TH/2muvdfUIAAAA\n",
              "sElt8TEPAAAAWxoxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR\n",
              "8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQ\n",
              "GDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAA\n",
              "AIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMA\n",
              "AABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgx\n",
              "DwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACF\n",
              "EfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhalqzK9Y\n",
              "sSJnn312Bg4cuMH1+fPnZ+TIkTn55JMzduzYLF++fL31Z599Nvvvv38WL15czTEBAACgKFWN+XPP\n",
              "PTf9+/ff4FpbW1suuuiiXHfddZkxY0YOPPDA3HTTTe3rq1atyuWXX5699tqrmiMCAABAcaoa89df\n",
              "f30GDRq0wbUFCxZk9913zx577JEkGTFiRObNm9e+fu211+bP//zPs+OOO37ge6xevTorV67s8M+6\n",
              "des22fUAAADA5mCbar54jx493nfr/HtaW1vT0NDQftzQ0JCWlpYkyU9/+tM0NzfnkksuyQ9+8IMP\n",
              "fI9p06Zl6tSpHa7369fvI0wOAAAAm6+qxnxnVCqV1NTU5K233so111yT2267baOeN3bs2Jx66qkd\n",
              "rt9www2baEIAAADYPHRZzPfu3Tutra3txy0tLWlsbMxPfvKT/Pa3v80ZZ5yRJHn++edz5pln5rrr\n",
              "rsvnP//5971OfX196uvrO3yfurq6TT88AAAAdKEui/mmpqY0NzfnxRdfzJ577plZs2Zl2LBhOeKI\n",
              "I3LEEUe0nzd69OhMmTIlu+22W1eNCgAAAJuVqsX8smXLctZZZ6WtrS3Lly/P6NGjs++++6a2tjbH\n",
              "HHNMmpqacuWVV+bCCy9MXV1dGhoaMnny5GqNAwAAAFuMmkqlUunqIappypQpmTBhQlePAQAAAJtM\n",
              "VX81HQAAALDpiXkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgH\n",
              "AACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKI\n",
              "eQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAo\n",
              "jJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAA\n",
              "gMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkA\n",
              "AAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyY\n",
              "BwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDC\n",
              "iHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAA\n",
              "KIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAAChMVWN+\n",
              "xYoVOfvsszNw4MANrs+fPz8jR47MySefnLFjx2b58uVJkoULF+bEE0/M1772tZxwwgl57rnnqjkm\n",
              "AAAAFKWqMX/uueemf//+G1xra2vLRRddlOuuuy4zZszIgQcemJtuuilJMm7cuIwfPz7Tp0/PX/7l\n",
              "X2by5MnVHBMAAACKUtWYv/766zNo0KANri1YsCC777579thjjyTJiBEjMm/evCTJ/fffny996UtJ\n",
              "kl69emXp0qUdvsfq1auzcuXKDv+sW7duk14TAAAAdLVtqvniPXr0aL91/v9qbW1NQ0ND+3FDQ0Na\n",
              "WlqSJD179kySvPvuu5k2bVqOP/74Dt9j2rRpmTp1aofr/fr1+yijAwAAwGarqjHfGZVKJTU1Ne3H\n",
              "q1evzrhx49KrV6984xvf6PB5Y8eOzamnntrh+g033LApxwQAAIAu12Ux37t377S2trYft7S0pLGx\n",
              "McnvQv5b3/pWDjzwwJxzzjkf+Dr19fWpr6/vcL2urm7TDAwAAACbiS771XRNTU1pbm7Oiy++mCSZ\n",
              "NWtWhg0bliS59tpr09TU9KEhDwAAAFujqn0yv2zZspx11llpa2vL8uXLM3r06Oy7776pra3NMccc\n",
              "k6amplx55ZW58MILU1dXl4aGhkyePDmrVq3KjBkzcsABB2T06NHtr3fHHXf4lB0AAACS1FQqlUpX\n",
              "D1FNU6ZMyYQJE7p6DAAAANhkuuw2ewAAAOCjEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAA\n",
              "AFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEP\n",
              "AAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR\n",
              "8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQ\n",
              "GDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAA\n",
              "AIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMA\n",
              "AABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgx\n",
              "DwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDEPAAAAhRHzAAAAUBgxDwAAAIUR8wAAAFCYbTr7hNdf\n",
              "fz2vvvpqkqRPnz757Gc/u8mHAgAAADq20TE/e/bsfP/738+SJUuy6667Jkmam5vTq1evnH766Tnq\n",
              "qKOqNiQAAADwvzYq5i+88MKsW7cu11xzTfr27bve2n/913/l7/7u7/LEE0/kyiuvrMqQAAAAwP/a\n",
              "qJgfMGBAvvrVr25wrW/fvrn22msza9asTTkXAAAA0IGN+gF4M2fOzH//9393uL5o0aLMnDlzkw0F\n",
              "AAAAdGyjPpmfNGlSzj///Oy8884ZNGhQevfuneR335l/8skn8+abb+bqq6+u6qAAAADA72xUzH/+\n",
              "85/PAw88kMcffzzz5s3Lk08+mSTp3bt3TjrppAwZMqSqQwIAAAD/q1O/mq579+657LLL1nts9uzZ\n",
              "m3QgAAAA4INtVMy/8soreemll3LttdfmggsuSKVSSZL2n3Dv19IBAADAJ2ejYv43v/lN/uVf/iWv\n",
              "vfZa/vZv/7b98dra2px00klVGw4AAAB4v42K+YMOOigHHXRQBg8enMMPP7zaMwEAAAAfoFPfmd9r\n",
              "r71y1VVXZfny5e232ifJlClTNvlgAAAAwIZ1Kua/853vZMiQIWlqatqo81esWJG//uu/zs9+9rP8\n",
              "5Cc/ed/6/PnzM3Xq1Gy77bbp0aNHrr766uywww755S9/mSuuuCJ1dXWpq6vL5MmTs9tuu3VmVAAA\n",
              "ANhidSrmP/OZz+Tcc8/d6PPPPffcDBs2LD/72c/et9bW1paLLrooM2bMyB577JGpU6fmpptuysUX\n",
              "X5wLL7wwkyZNyqGHHpoHH3wwl19++Xrf1QcAAICtWW1nTj744IOzaNGijT7/+uuvz6BBgza4tmDB\n",
              "guy+++7ZY489kiQjRozIvHnzsnjx4qxcuTKHHnpokuSoo47K008/nbVr127wdVavXp2VK1d2+Gfd\n",
              "unWduUQAAADY7HXqk/kf//jHue2227LDDjukrq6u/fGnnnpqg+f36NEjy5cv3+Baa2trGhoa2o8b\n",
              "GhrS0tKS1tbW7Lzzzu2P19fXp3v37lmyZEl22WWX973OtGnTMnXq1A5n7tev34deFwAAAJSkUzFf\n",
              "zVvdK5VKampqOlzvaG3s2LE59dRTO3zeDTfc8HFHAwAAgM1Kp2J+Q999T5I+ffp0+o179+6d1tbW\n",
              "9uOWlpY0Nja+7/Hf/va3aWtry0477bTB16mvr099fX2H7/P7dxAAAADAlqBTMf/EE0+0//OaNWuy\n",
              "cOHCHHroofnqV7/a6TduampKc3NzXnzxxey5556ZNWtWhg0blt69e6dXr1555pln0r9///zoRz/K\n",
              "4MGDRTkAAAD8f52K+e9973vrHa9cuTKXXnrpBs9dtmxZzjrrrLS1tWX58uUZPXp09t1339TW1uaY\n",
              "Y45JU1NTrrzyylx44YWpq6tLQ0NDJk+enCS56qqrctlll6Wmpibbbbed32MPAAAAv6dTMf9/bb/9\n",
              "9vn1r3+9wbXPfOYzufvuuz/w+QMGDMiAAQPe93jfvn1z7733fpzRAAAAYIvVqZg/99xz1/tBdK+9\n",
              "9lq6deu2yYcCAAAAOtapmP/93xlfU1OTnj175o//+I83+VAAAABAxzoV88cee2xaWlryH//xH6mp\n",
              "qckXv/jFdO/evVqzAQAAABvQqZj/wQ9+kBtvvDFf+MIXUqlUsmjRoowbNy4jRoyo1nwAAADA/9Gp\n",
              "mJ85c2b++Z//OZ/61KeSJCtWrMhf/MVfiHkAAAD4BNV25uRtt922PeSTpGfPnqmvr9/kQwEAAAAd\n",
              "69Qn8z169Mitt96agQMHJkmeeuqp9OzZsyqDAQAAABvWqZi//PLLc80112T27NmpqanJLrvskquu\n",
              "uqpaswEAAAAb0Knb7O+///4sWbIkDz74YH74wx9m7dq1uf/++6s1GwAAALABnYr5uXPn5pZbbmk/\n",
              "vu222/LYY49t8qEAAACAjnUq5tetW5e6urr243fffTeVSmWTDwUAAAB0rFPfmR82bFhGjhyZQw45\n",
              "JO+++27+9V//NUcffXS1ZgMAAAA2oFMxf/rpp6d///5ZsGBBampqMmnSpHzpS1+q0mgAAADAhnQq\n",
              "5pPk4IMPzsEHH1yNWQAAAICN0KnvzAMAAABdT8wDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMA\n",
              "AEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8\n",
              "AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRG\n",
              "zAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABA\n",
              "YcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAA\n",
              "ABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswD\n",
              "AABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHE\n",
              "PAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFGabar74tGnTMmfOnNTV1aWpqSkTJ05MTU1N\n",
              "+/pdd92VBx98MN27d89BBx2UcePGpaamJrNnz85dd92VbbfdNpVKJRdffHH69u1bzVEBAACgGFX7\n",
              "ZH7hwoV56KGHMn369Nx77715/vnnM2fOnPb1RYsW5c4778w999yTGTNm5I033sjcuXOzdu3aXHbZ\n",
              "Zbn11ltz991357jjjss111xTrTEBAACgOFWL+fnz52fo0KHp3r17amtrc+SRR2bevHnt6y+88EL2\n",
              "22+/bLfddkmSYcOG5fHHH09dXV0+/elPZ9myZUmS5cuXZ6eddqrWmAAAAFCcqt1m39ramv3226/9\n",
              "uKGhIa+//nr7cd++fXPFFVfkjTfeSK9evfLUU0+ltbU1NTU1ufzyy3Pcccdl5513zurVqzNjxowO\n",
              "32f16tVZvXp1h+vr1q3bNBcEAAAAm4mqfmf+91UqlfWO99xzz5x33nk588wz07NnzxxwwAFZunRp\n",
              "3n777Vx88cWZMWNG9tlnn8yaNSsXX3xxbrvttg2+7rRp0zJ16tQO37dfv36b9DoAAACgq1Ut5nfd\n",
              "dde0tra2Hzc3N6exsXG9c4499tgce+yxSZL77rsvb731Vv7nf/4nPXv2zD777JMkGTp0aC699NIO\n",
              "32fs2LE59dRTO1y/4YYbPsZVAAAAwOanat+ZHzJkSObOnZtVq1Zl7dq1mT17dg4//PD29RUrVmTU\n",
              "qFFZtWpV1qxZk5kzZ+YrX/lKdtttt7S0tOQ3v/lNkmTBggXZa6+9Onyf+vr6bL/99h3+qaurq9Yl\n",
              "AgAAQJeo2ifz+++/f0aOHJnRo0entrY2AwYMyODBg3POOefk/PPPT2NjY4YPH54TTjghtbW1Oeqo\n",
              "o9K/f/8kyaWXXpozzjgj3bp1S01NTSZPnlytMQEAAKA4NZX/+2X2LcyUKVMyYcKErh4DAAAANpmq\n",
              "3WYPAAAAVIeYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAA\n",
              "ACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgH\n",
              "AACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKI\n",
              "eQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAo\n",
              "jJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAA\n",
              "gMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkA\n",
              "AAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyY\n",
              "BwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDC\n",
              "iHkAAAAojJgHAACAwoh5AAAAKIyYBwAAgMKIeQAAACiMmAcAAIDCiHkAAAAojJgHAACAwmxTzRef\n",
              "Nm1a5syZk7q6ujQ1NWXixImpqalpX7/rrrvy4IMPpnv37jnooIMybty41NTUZOnSpRk/fnzefPPN\n",
              "vPvuu5kyZUr222+/ao4KAAAAxajaJ/MLFy7MQw89lOnTp+fee+/N888/nzlz5rSvL1q0KHfeeWfu\n",
              "ueeezJgxI2+88Ubmzp2bJLnqqqvSr1+/3H///fnOd76z3vMAAABga1e1T+bnz5+foUOHpnv37kmS\n",
              "I488MvPmzcvw4cOTJC+88EL222+/bLfddkmSYcOG5fHHH8+wYcMyZ86c9oAfPHhwBg8e3OH7rF69\n",
              "OqtXr+5wfd26dZvqkgAAAGCzULWYb21tXe/W+IaGhrz++uvtx3379s0VV1yRN954I7169cpTTz2V\n",
              "1tbW9lvrZ8+enUcffTT19fWZMGFC9t577w2+z7Rp0zJ16tQO5+jXr9+muygAAADYDFT1O/O/r1Kp\n",
              "rHe855575rzzzsuZZ56Znj175oADDsjSpUuTJKtWrcp+++2Xr33ta5k1a1YuuOCCPPDAAxt83bFj\n",
              "x+bUU0/t8H1vuOGGTXYNAAAAsDmoWszvuuuuaW1tbT9ubm5OY2Pjeucce+yxOfbYY5Mk9913X956\n",
              "663stNNO2W677XLYYYclSYYPH56JEyemUqms98Pz3lNfX5/6+voO56irq9sUlwMAAACbjar9ALwh\n",
              "Q4Zk7ty5WbVqVdauXZvZs2fn8MMPb19fsWJFRo0alVWrVmXNmjWZOXNmvvKVr6S2tjZ/8id/kief\n",
              "fDJJ8u///u/Zd999NxjyAAAAsDWq2ifz+++/f0aOHJnRo0entrY2AwYMyODBg3POOefk/PPPT2Nj\n",
              "Y4YPH54TTjghtbW1Oeqoo9K/f/8kySWXXJLx48fnlltuSU1NTa644opqjQkAAADFqan83y+zb2Gm\n",
              "TJmSCRMmdPUYAAAAsMlU7TZ7AAAAoDrEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbM\n",
              "AwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBh\n",
              "xDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAA\n",
              "FEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMA\n",
              "AEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8\n",
              "AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRG\n",
              "zAMAAEBhxDwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGHEPAAAABRGzAMAAEBhxDwAAAAURswDAABA\n",
              "YWoqlUqlq4eopr/6q7/Kbrvt1tVj0EXWrVuXhQsXpqmpKXV1dV09Dnwg+5WS2K+UxH6lJPYrSdLY\n",
              "2JgxY8Z84DlbfMyzdVu5cmUOOeSQ/PznP8/222/f1ePAB7JfKYn9SknsV0piv7Kx3GYPAAAAhRHz\n",
              "AAAAUBgxDwAAAIUR8wAAAFAYMQ8AAACFEfMAAABQGDHPFq2+vj5nnnlm6uvru3oU+FD2KyWxXymJ\n",
              "/UpJ7Fc2lt8zDwAAAIXxyTwAAAAURswDAABAYcQ8AAAAFEbMAwAAQGG26eoBYFN45ZVXMnHixKxb\n",
              "ty7vvvtuLrnkknzxi19c75ylS5dm/Pjxeeutt7JmzZp8+9vfzqBBg9rX16xZk1GjRmXo0KE566yz\n",
              "PulLYCvycfbrO++8k4svvjiLFy9OW1tbjj766Jx22mlddCVsyaZNm5Y5c+akrq4uTU1NmThxYmpq\n",
              "atrXf/jDH+aee+7JNttsk9122y2TJ09OfX195s+fn6lTp2bbbbdNjx49cvXVV2eHHXbowithS/dx\n",
              "92q3bt1SU1OTyZMnZ/fdd+/CK2Fr8FH363seffTRfPvb386iRYu6Ynw2NxXYApx22mmVBx98sFKp\n",
              "VCr/9m//VhkxYsT7zrn00ksrN998c6VSqVReeumlyqBBgyptbW3t69/73vcqJ554YuXGG2/8ZIZm\n",
              "q/Vx9ustt9xSueSSSyqVSqWyatWqyqBBgyovvfTSJzc8W4Vnn322MmLEiMqqVasq69atq5xyyimV\n",
              "Rx99tH29ubm58uUvf7myZMmSSqVSqYwfP75y++23V955553KwIEDKy+//HKlUqlUbrrppsrf/M3f\n",
              "dMk1sHX4OHv1D//wDyuvvvpqpVKpVO68887KuHHjuuQa2Hp81P36njfeeKNy/PHHVwYOHPiJz87m\n",
              "yW32FG/NmjV55plncuSRRyZJDjvssCxbtizNzc3rnffEE0/k6KOPTpJ87nOfS2NjYxYuXJgkefbZ\n",
              "Z/Pcc8/l+OOP/2SHZ6vzcffrN7/5zUycODFJ0r1793zqU5/KsmXLPtFrYMs3f/78DB06NN27d09t\n",
              "bW2OPPLIzJs3r339pz/9aQ477LDsuOOOSZIRI0Zk3rx5WbBgQXbffffsscce6z0O1fJR92q3bt3y\n",
              "2GOPpbGxMUnSq1evLF26tCsuga3IR92v77nkkksybtw4v3+edmKe4i1ZsiTbbbfdev9ia2hoSEtL\n",
              "y3rntba2Zuedd24/3mWXXdLS0pJ33nknkyZNyqRJk9a7zQmq4ePu1/r6+nTv3j1J8sgjj6Rbt245\n",
              "4IADPpnh2Wq0tramoaGh/bihoSGvv/76B663tLR0+DhUy0fdq0nSo0ePJElbW1tuv/12/0Ofqvs4\n",
              "+3XmzJnp06dP+vfv/8kNzGbPd+YpyiOPPJLvf//76z32zjvvbPDcDwvzSqWSmpqaXHPNNTnxxBPT\n",
              "p0+fTTYnJNXZr+/5p3/6p9x88825/fbbU1dX9/GHhQ9QqVQ+dH1De7ijx6FaOrtXV6xYkW9961sZ\n",
              "NmxYjjjiiGqPB+vZ2P26ePHi3Hvvvbnnnns+ockohZinKEccccT7/mO7du3aHHLIIWlra0u3bt2S\n",
              "JC0tLendu/d65+26665pbW3NnnvumSRpbm5O7969M3fu3Pzyl7/MzJkzs2TJkqxevTqf/vSn841v\n",
              "fOOTuSi2WNXYr8nv/u/8P/7jP2b69OnrfXoPm8p7++89zc3N7bcjv7f+q1/9qv24paUljY2N6d27\n",
              "93rPe+9xqJaPuleT34X8KaecklGjRuXEE0/85IZmq/VR9+tjjz2Wtra2jBkzJsnvPsEfNWpU/v7v\n",
              "/779DhO2Tm6zp3jbbLNNBg4cmIcffjhJ8uSTT6axsTGf/exn1ztvyJAheeihh5Ikv/rVr/Lmm2+m\n",
              "qakp8+bNy3333Zf77rsvZ5xxRkaOHCnkqZqPu1+fe+653H333bnjjjuEPFUzZMiQzJ07N6tWrcra\n",
              "tWsze/bsHH744e3rAwcOzM9//vMsWbIkSfKjH/0ow4YNS1NTU5qbm/Piiy8mSWbNmpVhw4Z1yTWw\n",
              "dfioezVJJkyYkJNOOknI84n5qPv1lFNOycMPP9z+99Vddtkl9913n5AnNZUPu78DCtDc3JwJEyZk\n",
              "9erVqa2tzXe/+93svffeeeKJJ7Jw4cKceeaZeeutt3LBBRdk2bJlqVQqGTduXA499ND1XueBBx7I\n",
              "q6++6lfTUVUfZ7+ed955efbZZ9f7JP+b3/xm/vRP/7TrLogt0h133JGHHnootbW1GTBgQM4555yc\n",
              "c845Of/889PY2JiHHnoo//AP/5Btt902++yzTy699NJss802efrpp3P99denrq4uDQ0NmTx5crbf\n",
              "fvuuvhy2YB9lry5evDhHHnnken8P2HHHHXPjjTd24ZWwNfio/279fUOHDs2Pf/zjLroCNidiHgAA\n",
              "AArjNnsAAAAojJgHAACAwoh5AAAAKIyYBwDyn//5n/nud7+70eePGjUqzzzzTPUGAgA+kJgHAPKF\n",
              "L3yhUzEPAHStbT78FABgS/fMM8/kuuuuS7du3TJw4MD84he/yMsvv5yTTz45Y8aMyZIlS3L22Wdn\n",
              "zZo1+dznPpc1a9a0P3f69OmZPXt23n333fTp0yeXXXZZXnzxxUyYMCEPPPBAamtrM2rUqFx00UU5\n",
              "5JBDuvAqAWDLIeYBgPUsXbo0t956a1544YWcdNJJGTNmTO68887sv//+GT9+fF577bUMHz48SbJw\n",
              "4cI88sgjmT59empra3P99dfnrrvuyhlnnJHhw4fn1ltvTX19fQYMGCDkAWATEvMAwHr+6I/+KEnS\n",
              "p0+fLFu2LEmyaNGiHHfccUmSxsbG/MEf/EGS332iv3jx4owZMyZJsmrVquy///5JktNPPz2jR4/O\n",
              "mjVrcu+9936yFwEAWzgxDwCsp66u7n2PVSqV1NTUtB+vW7cuSVJfX58vf/nLmTRp0vue09bWlnfe\n",
              "eSfr1q3L22+/nfr6+uoNDQBbGT8ADwD4UHvvvXd+8YtfJEleeeWV/PrXv06SHHzwwXnqqaeycuXK\n",
              "JMnMmTPz9NNPJ0muvPLKnHzyyTnttNNy2WWXdc3gALCFEvMAwIcaM2ZMnn322YwePTo333xzDjzw\n",
              "wCTJgQcemK9//ev5+te/npNPPjnz5s3LAQcckPnz5+fll1/OyJEj82d/9md5++238/DDD3fxVQDA\n",
              "lqOmUqlUunoIAAAAYOP5ZB4AAAAKI+YBAACgMGIeAAAACiPmAQAAoDBiHgAAAAoj5gEAAKAwYh4A\n",
              "AAAKI+YBAACgMGIeAAAACiPmAQAAoDD/D6KvCk6dI4RLAAAAAElFTkSuQmCC\n",
              "\">\n",
              "      </div>\n",
              "      <script type=\"text/javascript\">\n",
              "        (() => {\n",
              "          const chartElement = document.getElementById(\"chart-476f6cae-4c75-4a60-afd4-6328696be4d3\");\n",
              "          async function getCodeForChartHandler(event) {\n",
              "            const chartCodeResponse =  await google.colab.kernel.invokeFunction(\n",
              "                'getCodeForChart', [\"chart-476f6cae-4c75-4a60-afd4-6328696be4d3\"], {});\n",
              "            const responseJson = chartCodeResponse.data['application/json'];\n",
              "            await google.colab.notebook.addCell(responseJson.code, 'code');\n",
              "          }\n",
              "          chartElement.onclick = getCodeForChartHandler;\n",
              "        })();\n",
              "      </script>\n",
              "      <style>\n",
              "        .colab-quickchart-chart-with-code  {\n",
              "            display: block;\n",
              "            float: left;\n",
              "            border: 1px solid transparent;\n",
              "        }\n",
              "\n",
              "        .colab-quickchart-chart-with-code:hover {\n",
              "            cursor: pointer;\n",
              "            border: 1px solid #aaa;\n",
              "        }\n",
              "      </style>"
            ],
            "text/plain": [
              "from matplotlib import pyplot as plt\n",
              "import seaborn as sns\n",
              "def _plot_series(series, series_name, series_index=0):\n",
              "  from matplotlib import pyplot as plt\n",
              "  import seaborn as sns\n",
              "  palette = list(sns.palettes.mpl_palette('Dark2'))\n",
              "  counted = (series['index']\n",
              "                .value_counts()\n",
              "              .reset_index(name='counts')\n",
              "              .rename({'index': 'index'}, axis=1)\n",
              "              .sort_values('index', ascending=True))\n",
              "  xs = counted['index']\n",
              "  ys = counted['counts']\n",
              "  plt.plot(xs, ys, label=series_name, color=palette[series_index % len(palette)])\n",
              "\n",
              "fig, ax = plt.subplots(figsize=(10, 5.2), layout='constrained')\n",
              "df_sorted = _df_0.sort_values('index', ascending=True)\n",
              "_plot_series(df_sorted, '')\n",
              "sns.despine(fig=fig, ax=ax)\n",
              "plt.xlabel('index')\n",
              "_ = plt.ylabel('count()')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dfs = []\n",
        "config_dfs = []\n",
        "for model in models:\n",
        "    # vanilla = json.load(open(f'./merged_eval_results/greedy/{model}_with_sys_prompt_summary.json', 'r'))\n",
        "    data = json.load(open(f'./merged_eval_results/exploited/{model}_summary.json', 'r'))\n",
        "    data_cp = {'model': model}\n",
        "    config_cp = {'model': model}\n",
        "    for (k,v) in data.items():\n",
        "        if k != 'best_attack_config':\n",
        "            data_cp[k] = v\n",
        "        else:\n",
        "            for kk, vv in v.items():\n",
        "                config_cp[kk] = (list(vv.keys())[0].split('_')[1], list(vv.values())[0])\n",
        "    dfs.append(pd.DataFrame([data_cp]))\n",
        "    config_dfs.append(pd.DataFrame([config_cp]))\n",
        "pd.concat(dfs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EERN00NVqliR"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/Jailbreak_LLM/vicuna-7b-v1.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rG6WPxTeqpGb",
        "outputId": "0d9d3417-c79d-4c45-c87a-bbd65fdf5793"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wV8wrsjRqbI3",
        "outputId": "75c70b01-fc85-434c-8dd9-1b7d66734e79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Git LFS initialized.\n",
            "Cloning into 'vicuna-7b-v1.5'...\n",
            "remote: Enumerating objects: 42, done.\u001b[K\n",
            "remote: Total 42 (delta 0), reused 0 (delta 0), pack-reused 42\u001b[K\n",
            "Unpacking objects: 100% (42/42), 6.77 KiB | 693.00 KiB/s, done.\n",
            "Filtering content: 100% (3/3), 4.55 GiB | 39.76 MiB/s, done.\n",
            "Encountered 1 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model-00001-of-00002.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone https://huggingface.co/lmsys/vicuna-7b-v1.5\n",
        "\n",
        "# if you want to clone without large files – just their pointers\n",
        "# prepend your git clone with the following env var:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHIXTy5frHHh",
        "outputId": "8bc67246-085a-4012-a208-9e0244b7d740"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:27<00:00, 13.73s/it]\n",
            "INFO:root:Model size: 13.543948288\n",
            "INFO:root:Model name: vicuna-7b-v1.5\n",
            "INFO:root:Running temp = 0.05\n",
            "100% 100/100 [05:35<00:00,  3.35s/it]\n",
            "INFO:root:Running temp = 0.1\n",
            "100% 100/100 [05:39<00:00,  3.39s/it]\n",
            "INFO:root:Running temp = 0.15\n",
            "100% 100/100 [05:37<00:00,  3.37s/it]\n",
            "INFO:root:Running temp = 0.2\n",
            "100% 100/100 [05:38<00:00,  3.38s/it]\n",
            "INFO:root:Running temp = 0.25\n",
            "100% 100/100 [05:41<00:00,  3.41s/it]\n",
            "INFO:root:Running temp = 0.3\n",
            "100% 100/100 [05:40<00:00,  3.41s/it]\n",
            "INFO:root:Running temp = 0.35\n",
            "100% 100/100 [05:39<00:00,  3.40s/it]\n",
            "INFO:root:Running temp = 0.4\n",
            "100% 100/100 [05:31<00:00,  3.31s/it]\n",
            "INFO:root:Running temp = 0.45\n",
            "100% 100/100 [05:38<00:00,  3.38s/it]\n",
            "INFO:root:Running temp = 0.5\n",
            "100% 100/100 [05:32<00:00,  3.33s/it]\n",
            "INFO:root:Running temp = 0.55\n",
            "100% 100/100 [05:27<00:00,  3.27s/it]\n",
            "INFO:root:Running temp = 0.6\n",
            "100% 100/100 [05:23<00:00,  3.24s/it]\n",
            "INFO:root:Running temp = 0.65\n",
            "100% 100/100 [05:31<00:00,  3.31s/it]\n",
            "INFO:root:Running temp = 0.7\n",
            "100% 100/100 [05:24<00:00,  3.24s/it]\n",
            "INFO:root:Running temp = 0.75\n",
            "100% 100/100 [05:13<00:00,  3.13s/it]\n",
            "INFO:root:Running temp = 0.8\n",
            "100% 100/100 [04:57<00:00,  2.97s/it]\n",
            "INFO:root:Running temp = 0.85\n",
            "100% 100/100 [05:16<00:00,  3.17s/it]\n",
            "INFO:root:Running temp = 0.9\n",
            "100% 100/100 [05:03<00:00,  3.04s/it]\n",
            "INFO:root:Running temp = 0.95\n",
            "100% 100/100 [05:23<00:00,  3.23s/it]\n",
            "INFO:root:Running temp = 1.0\n",
            "100% 100/100 [04:49<00:00,  2.89s/it]\n",
            "INFO:root:Running topp = 0.0\n",
            "100% 100/100 [05:53<00:00,  3.53s/it]\n",
            "INFO:root:Running topp = 0.05\n",
            "100% 100/100 [05:51<00:00,  3.51s/it]\n",
            "INFO:root:Running topp = 0.1\n",
            "100% 100/100 [05:55<00:00,  3.55s/it]\n",
            "INFO:root:Running topp = 0.15\n",
            "100% 100/100 [05:43<00:00,  3.43s/it]\n",
            "INFO:root:Running topp = 0.2\n",
            "100% 100/100 [05:35<00:00,  3.36s/it]\n",
            "INFO:root:Running topp = 0.25\n",
            "100% 100/100 [05:43<00:00,  3.44s/it]\n",
            "INFO:root:Running topp = 0.3\n",
            "100% 100/100 [06:08<00:00,  3.68s/it]\n",
            "INFO:root:Running topp = 0.35\n",
            "100% 100/100 [05:52<00:00,  3.53s/it]\n",
            "INFO:root:Running topp = 0.4\n",
            "100% 100/100 [05:49<00:00,  3.49s/it]\n",
            "INFO:root:Running topp = 0.45\n",
            "100% 100/100 [06:02<00:00,  3.63s/it]\n",
            "INFO:root:Running topp = 0.5\n",
            "100% 100/100 [05:38<00:00,  3.39s/it]\n",
            "INFO:root:Running topp = 0.55\n",
            "100% 100/100 [05:36<00:00,  3.36s/it]\n",
            "INFO:root:Running topp = 0.6\n",
            "100% 100/100 [05:21<00:00,  3.21s/it]\n",
            "INFO:root:Running topp = 0.65\n",
            "100% 100/100 [05:23<00:00,  3.23s/it]\n",
            "INFO:root:Running topp = 0.7\n",
            "100% 100/100 [04:35<00:00,  2.76s/it]\n",
            "INFO:root:Running topp = 0.75\n",
            "100% 100/100 [04:32<00:00,  2.73s/it]\n",
            "INFO:root:Running topp = 0.8\n",
            "100% 100/100 [04:45<00:00,  2.86s/it]\n",
            "INFO:root:Running topp = 0.85\n",
            "100% 100/100 [04:28<00:00,  2.68s/it]\n",
            "INFO:root:Running topp = 0.9\n",
            "100% 100/100 [04:48<00:00,  2.88s/it]\n",
            "INFO:root:Running topp = 0.95\n",
            "100% 100/100 [04:12<00:00,  2.52s/it]\n",
            "INFO:root:Running topp = 1.0\n",
            "100% 100/100 [04:16<00:00,  2.56s/it]\n",
            "INFO:root:Running topk = 1\n",
            "100% 100/100 [05:56<00:00,  3.57s/it]\n",
            "INFO:root:Running topk = 2\n",
            "100% 100/100 [06:01<00:00,  3.61s/it]\n",
            "INFO:root:Running topk = 5\n",
            "100% 100/100 [05:35<00:00,  3.36s/it]\n",
            "INFO:root:Running topk = 10\n",
            "100% 100/100 [05:24<00:00,  3.24s/it]\n",
            "INFO:root:Running topk = 20\n",
            "100% 100/100 [04:54<00:00,  2.94s/it]\n",
            "INFO:root:Running topk = 50\n",
            "100% 100/100 [04:56<00:00,  2.97s/it]\n",
            "INFO:root:Running topk = 100\n",
            "100% 100/100 [05:07<00:00,  3.07s/it]\n",
            "INFO:root:Running topk = 200\n",
            "100% 100/100 [04:52<00:00,  2.92s/it]\n",
            "INFO:root:Running topk = 500\n",
            "100% 100/100 [04:42<00:00,  2.83s/it]\n"
          ]
        }
      ],
      "source": [
        "!python attack.py \\\n",
        "    --model vicuna-7b-v1.5 \\\n",
        "    --tune_temp \\\n",
        "    --tune_topp \\\n",
        "    --tune_topk \\\n",
        "    --n_sample 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "5aJtNQwFrtwG",
        "outputId": "f74f5d6e-d7ff-4185-842d-8c1e4d38c337"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usage: attack.py [-h] [--model MODEL] [--n_sample N_SAMPLE] [--use_greedy] [--use_default]\n",
            "                 [--tune_temp] [--tune_topp] [--tune_topk] [--use_system_prompt] [--use_advbench]\n",
            "attack.py: error: unrecognized arguments: \\\n"
          ]
        }
      ],
      "source": [
        "!python attack.py \\\n",
        "    --model flan-t5-small \\\n",
        "    --use_greedy \\"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WRZfzmO3r2FK"
      },
      "outputs": [],
      "source": [
        "!python evaluate.py \\\n",
        "    --model vicuna-7b-v1.5 \\\n",
        "    --evaluator_path /content/Jailbreak_LLM/evaluator \\\n",
        "    --scorer_path /content/Jailbreak_LLM/scorer/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git lfs install\n",
        "!GIT_LFS_SKIP_SMUDGE=1\n",
        "!git clone https://huggingface.co/tiiuae/falcon-7b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16j0NzS6T3WB",
        "outputId": "d3cb4cf0-ce96-4c43-cfc2-e0835dab9fc2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "Cloning into 'falcon-7b'...\n",
            "remote: Enumerating objects: 97, done.\u001b[K\n",
            "remote: Counting objects: 100% (37/37), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 97 (delta 24), reused 13 (delta 13), pack-reused 60\u001b[K\n",
            "Unpacking objects: 100% (97/97), 817.64 KiB | 1.20 MiB/s, done.\n",
            "Filtering content: 100% (2/2), 1.44 GiB | 2.76 MiB/s, done.\n",
            "Encountered 2 file(s) that may not have been copied correctly on Windows:\n",
            "\tpytorch_model-00002-of-00002.bin\n",
            "\tpytorch_model-00001-of-00002.bin\n",
            "\n",
            "See: `git lfs help smudge` for more details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jM0TYHK7Wcbz",
        "outputId": "87c24374-616f-4fe0-ea0f-6d9bff8fd434"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting accelerate\n",
            "  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.25.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model falcon-7b \\\n",
        "    --use_greedy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAGpKnMESlIF",
        "outputId": "81b3bac0-bd5b-4f47-a19a-10c62def8401"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:transformers_modules.falcon-7b.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n",
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:13<00:00,  6.83s/it]\n",
            "INFO:root:Model size: 13.843445504\n",
            "INFO:root:Model name: falcon-7b\n",
            "INFO:root:Running greedy\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:11<18:12, 11.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:18<14:48,  9.06s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:26<13:37,  8.42s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:34<13:00,  8.13s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:41<12:38,  7.98s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:49<12:20,  7.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:57<12:06,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:04<11:54,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:12<11:44,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:20<11:36,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:27<11:27,  7.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:35<11:21,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:43<11:12,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:51<11:04,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [01:58<10:56,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:06<10:49,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:14<10:42,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:22<10:34,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:29<10:27,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:37<10:20,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:45<10:12,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [02:53<10:04,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [03:00<09:56,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:08<09:48,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 25% 25/100 [03:16<09:40,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 26% 26/100 [03:24<09:33,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 27% 27/100 [03:31<09:25,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 28% 28/100 [03:39<09:18,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 29% 29/100 [03:47<09:11,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 30% 30/100 [03:55<09:03,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 31% 31/100 [04:02<08:55,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 32% 32/100 [04:10<08:47,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 33% 33/100 [04:18<08:40,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 34% 34/100 [04:26<08:32,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 35% 35/100 [04:33<08:24,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 36% 36/100 [04:41<08:16,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 37% 37/100 [04:49<08:08,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 38% 38/100 [04:57<08:00,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 39% 39/100 [05:04<07:52,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 40% 40/100 [05:12<07:45,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 41% 41/100 [05:20<07:38,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 42% 42/100 [05:28<07:30,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 43% 43/100 [05:36<07:22,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 44% 44/100 [05:43<07:14,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 45% 45/100 [05:51<07:06,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 46% 46/100 [05:59<06:58,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 47% 47/100 [06:07<06:51,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 48% 48/100 [06:14<06:43,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 49% 49/100 [06:22<06:35,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 50% 50/100 [06:30<06:28,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 51% 51/100 [06:38<06:20,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 52% 52/100 [06:45<06:13,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 53% 53/100 [06:53<06:06,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 54% 54/100 [07:01<05:58,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 55% 55/100 [07:09<05:50,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 56% 56/100 [07:17<05:42,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 57% 57/100 [07:24<05:35,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 58% 58/100 [07:32<05:27,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 59% 59/100 [07:40<05:19,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 60% 60/100 [07:48<05:11,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 61% 61/100 [07:55<05:02,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 62% 62/100 [08:03<04:55,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 63% 63/100 [08:11<04:47,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 64% 64/100 [08:19<04:39,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 65% 65/100 [08:27<04:31,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 66% 66/100 [08:34<04:23,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 67% 67/100 [08:42<04:16,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 68% 68/100 [08:50<04:08,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 69% 69/100 [08:58<04:01,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 70% 70/100 [09:05<03:53,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 71% 71/100 [09:13<03:45,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 72% 72/100 [09:21<03:38,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 73% 73/100 [09:29<03:30,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 74% 74/100 [09:37<03:22,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 75% 75/100 [09:44<03:14,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 76% 76/100 [09:52<03:06,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 77% 77/100 [10:00<02:59,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 78% 78/100 [10:05<02:32,  6.94s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 79% 79/100 [10:13<02:30,  7.18s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 80% 80/100 [10:20<02:27,  7.37s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 81% 81/100 [10:28<02:22,  7.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 82% 82/100 [10:36<02:16,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 83% 83/100 [10:44<02:09,  7.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 84% 84/100 [10:52<02:02,  7.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 85% 85/100 [10:59<01:55,  7.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 86% 86/100 [11:07<01:48,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 87% 87/100 [11:15<01:40,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 88% 88/100 [11:23<01:33,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 89% 89/100 [11:31<01:25,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 90% 90/100 [11:38<01:17,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 91% 91/100 [11:46<01:09,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 92% 92/100 [11:54<01:02,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 93% 93/100 [12:02<00:54,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 94% 94/100 [12:09<00:46,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 95% 95/100 [12:17<00:38,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 96% 96/100 [12:25<00:31,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 97% 97/100 [12:33<00:23,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 98% 98/100 [12:41<00:15,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 99% 99/100 [12:48<00:07,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "100% 100/100 [12:56<00:00,  7.77s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model falcon-7b \\\n",
        "    --use_default \\\n",
        "    --use_system_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wq3AtgWTZwFZ",
        "outputId": "3d4828e4-8bae-4718-a305-48fcdb8df9aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:transformers_modules.falcon-7b.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n",
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:14<00:00,  7.19s/it]\n",
            "INFO:root:Model size: 13.843445504\n",
            "INFO:root:Model name: falcon-7b_with_sys_prompt\n",
            "INFO:root:Running default, top_p=0.9, temp=0.1\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:09<16:21,  9.92s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:18<14:31,  8.89s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:26<13:51,  8.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:34<13:26,  8.40s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:42<13:10,  8.32s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:50<13:00,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:59<12:50,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:07<12:41,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:15<12:31,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:23<12:23,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:32<12:13,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:40<12:05,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:48<11:56,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:56<11:48,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [02:05<11:41,  8.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:13<11:33,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:21<11:26,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:29<11:18,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:38<11:11,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:46<11:03,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:54<10:55,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [03:03<10:46,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [03:11<10:37,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:19<10:29,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 25% 25/100 [03:27<10:20,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 26% 26/100 [03:36<10:12,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 27% 27/100 [03:44<10:04,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 28% 28/100 [03:52<09:56,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 29% 29/100 [04:01<09:48,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 30% 30/100 [04:09<09:39,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 31% 31/100 [04:17<09:30,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 32% 32/100 [04:25<09:22,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 33% 33/100 [04:34<09:14,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 34% 34/100 [04:42<09:06,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 35% 35/100 [04:50<08:58,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 36% 36/100 [04:58<08:48,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 37% 37/100 [05:07<08:40,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 38% 38/100 [05:15<08:32,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 39% 39/100 [05:23<08:23,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 40% 40/100 [05:31<08:15,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 41% 41/100 [05:40<08:08,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 42% 42/100 [05:48<07:59,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 43% 43/100 [05:56<07:51,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 44% 44/100 [06:05<07:43,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 45% 45/100 [06:13<07:34,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 46% 46/100 [06:21<07:26,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 47% 47/100 [06:29<07:18,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 48% 48/100 [06:38<07:10,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 49% 49/100 [06:46<07:01,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 50% 50/100 [06:54<06:54,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 51% 51/100 [07:03<06:45,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 52% 52/100 [07:11<06:36,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 53% 53/100 [07:19<06:28,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 54% 54/100 [07:27<06:20,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 55% 55/100 [07:36<06:11,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 56% 56/100 [07:44<06:03,  8.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 57% 57/100 [07:52<05:55,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 58% 58/100 [08:00<05:47,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 59% 59/100 [08:09<05:38,  8.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 60% 60/100 [08:17<05:30,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 61% 61/100 [08:25<05:22,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 62% 62/100 [08:33<05:14,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 63% 63/100 [08:42<05:05,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 64% 64/100 [08:50<04:57,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 65% 65/100 [08:58<04:50,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 66% 66/100 [09:07<04:41,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 67% 67/100 [09:15<04:33,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 68% 68/100 [09:23<04:24,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 69% 69/100 [09:31<04:16,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 70% 70/100 [09:40<04:08,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 71% 71/100 [09:48<03:59,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 72% 72/100 [09:56<03:51,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 73% 73/100 [10:04<03:43,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 74% 74/100 [10:13<03:35,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 75% 75/100 [10:21<03:27,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 76% 76/100 [10:29<03:18,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 77% 77/100 [10:38<03:10,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 78% 78/100 [10:46<03:02,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 79% 79/100 [10:54<02:54,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 80% 80/100 [11:02<02:45,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 81% 81/100 [11:11<02:37,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 82% 82/100 [11:19<02:29,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 83% 83/100 [11:27<02:20,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 84% 84/100 [11:36<02:12,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 85% 85/100 [11:44<02:04,  8.29s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 86% 86/100 [11:52<01:56,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 87% 87/100 [12:01<01:47,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 88% 88/100 [12:09<01:39,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 89% 89/100 [12:17<01:31,  8.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 90% 90/100 [12:25<01:23,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 91% 91/100 [12:34<01:14,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 92% 92/100 [12:42<01:06,  8.30s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 93% 93/100 [12:50<00:57,  8.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 94% 94/100 [12:59<00:49,  8.27s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 95% 95/100 [13:07<00:41,  8.26s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 96% 96/100 [13:15<00:33,  8.25s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 97% 97/100 [13:23<00:24,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 98% 98/100 [13:31<00:16,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 99% 99/100 [13:40<00:08,  8.24s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "100% 100/100 [13:48<00:00,  8.28s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python attack.py \\\n",
        "    --model falcon-7b \\\n",
        "    --tune_temp \\\n",
        "    --tune_topp \\\n",
        "    --tune_topk \\\n",
        "    --n_sample 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AfbqxdHZ9tj",
        "outputId": "7c1ac215-fe8e-494c-c7bc-e34df01d8adf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:transformers_modules.falcon-7b.configuration_falcon:\n",
            "WARNING: You are currently loading Falcon using legacy code contained in the model repository. Falcon has now been fully ported into the Hugging Face transformers library. For the most up-to-date and high-performance version of the Falcon model code, please update to the latest version of transformers and then load the model without the trust_remote_code=True argument.\n",
            "\n",
            "INFO:accelerate.utils.modeling:We will use 90% of the memory on device 0 for storing the model, and 10% for the buffer to avoid OOM. You can set `max_memory` in to a higher value to use more memory (at your own risk).\n",
            "Loading checkpoint shards: 100% 2/2 [00:12<00:00,  6.23s/it]\n",
            "INFO:root:Model size: 13.843445504\n",
            "INFO:root:Model name: falcon-7b\n",
            "INFO:root:Running temp = 0.05\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:09<15:02,  9.12s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:16<13:36,  8.33s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:24<13:03,  8.08s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:32<12:45,  7.97s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:40<12:31,  7.91s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:48<12:19,  7.87s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:55<12:10,  7.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:03<11:59,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:11<11:50,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:19<11:42,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:27<11:36,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:34<11:28,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:42<11:20,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:50<11:11,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [01:58<11:04,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:06<10:55,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:13<10:47,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:21<10:39,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:29<10:32,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:37<10:24,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:45<10:16,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [02:52<10:08,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [03:00<10:01,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:08<09:52,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 25% 25/100 [03:16<09:45,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 26% 26/100 [03:24<09:37,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 27% 27/100 [03:32<09:30,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 28% 28/100 [03:39<09:22,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 29% 29/100 [03:47<09:14,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 30% 30/100 [03:55<09:06,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 31% 31/100 [04:03<08:59,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 32% 32/100 [04:11<08:51,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 33% 33/100 [04:18<08:43,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 34% 34/100 [04:26<08:35,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 35% 35/100 [04:34<08:27,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 36% 36/100 [04:42<08:19,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 37% 37/100 [04:50<08:11,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 38% 38/100 [04:57<08:04,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 39% 39/100 [05:05<07:56,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 40% 40/100 [05:13<07:47,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 41% 41/100 [05:21<07:39,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 42% 42/100 [05:29<07:31,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 43% 43/100 [05:36<07:23,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 44% 44/100 [05:44<07:16,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 45% 45/100 [05:52<07:07,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 46% 46/100 [06:00<07:00,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 47% 47/100 [06:07<06:52,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 48% 48/100 [06:15<06:44,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 49% 49/100 [06:23<06:36,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 50% 50/100 [06:31<06:29,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 51% 51/100 [06:39<06:21,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 52% 52/100 [06:46<06:14,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 53% 53/100 [06:54<06:06,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 54% 54/100 [07:02<05:58,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 55% 55/100 [07:10<05:50,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 56% 56/100 [07:18<05:43,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 57% 57/100 [07:25<05:35,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 58% 58/100 [07:33<05:27,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 59% 59/100 [07:41<05:19,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 60% 60/100 [07:49<05:11,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 61% 61/100 [07:57<05:04,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 62% 62/100 [08:04<04:56,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 63% 63/100 [08:12<04:48,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 64% 64/100 [08:20<04:40,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 65% 65/100 [08:28<04:32,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 66% 66/100 [08:36<04:24,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 67% 67/100 [08:43<04:17,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 68% 68/100 [08:51<04:09,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 69% 69/100 [08:59<04:02,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 70% 70/100 [09:07<03:54,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 71% 71/100 [09:15<03:46,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 72% 72/100 [09:22<03:38,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 73% 73/100 [09:30<03:30,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 74% 74/100 [09:38<03:23,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 75% 75/100 [09:46<03:15,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 76% 76/100 [09:54<03:07,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 77% 77/100 [10:02<02:59,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 78% 78/100 [10:07<02:33,  6.96s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 79% 79/100 [10:14<02:31,  7.21s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 80% 80/100 [10:22<02:27,  7.39s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 81% 81/100 [10:30<02:22,  7.51s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 82% 82/100 [10:38<02:16,  7.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 83% 83/100 [10:46<02:10,  7.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 84% 84/100 [10:53<02:03,  7.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 85% 85/100 [11:01<01:56,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 86% 86/100 [11:09<01:48,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 87% 87/100 [11:17<01:40,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 88% 88/100 [11:25<01:33,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 89% 89/100 [11:32<01:25,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 90% 90/100 [11:40<01:17,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 91% 91/100 [11:48<01:10,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 92% 92/100 [11:56<01:02,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 93% 93/100 [12:04<00:54,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 94% 94/100 [12:11<00:46,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 95% 95/100 [12:19<00:38,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 96% 96/100 [12:27<00:31,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 97% 97/100 [12:35<00:23,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 98% 98/100 [12:43<00:15,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 99% 99/100 [12:50<00:07,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "100% 100/100 [12:58<00:00,  7.79s/it]\n",
            "INFO:root:Running temp = 0.1\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:07<12:55,  7.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:15<12:46,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:23<12:39,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:31<12:31,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:39<12:23,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:46<12:15,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:54<12:06,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:02<11:59,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:10<11:51,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:18<11:43,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:26<11:35,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:33<11:27,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:41<11:20,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:49<11:13,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [01:57<11:04,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:05<10:56,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:12<10:49,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:20<10:40,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:28<10:33,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:36<10:25,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:44<10:18,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [02:52<10:10,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [02:59<10:02,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:07<09:54,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 25% 25/100 [03:15<09:47,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 26% 26/100 [03:23<09:39,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 27% 27/100 [03:31<09:30,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 28% 28/100 [03:38<09:22,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 29% 29/100 [03:46<09:16,  7.84s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 30% 30/100 [03:54<09:08,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 31% 31/100 [04:02<09:00,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 32% 32/100 [04:10<08:51,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 33% 33/100 [04:18<08:43,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 34% 34/100 [04:25<08:35,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 35% 35/100 [04:33<08:28,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 36% 36/100 [04:41<08:20,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 37% 37/100 [04:49<08:12,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 38% 38/100 [04:57<08:04,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 39% 39/100 [05:04<07:56,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 40% 40/100 [05:12<07:48,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 41% 41/100 [05:20<07:41,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 42% 42/100 [05:28<07:32,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 43% 43/100 [05:36<07:24,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 44% 44/100 [05:44<07:17,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 45% 45/100 [05:51<07:09,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 46% 46/100 [05:59<07:02,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 47% 47/100 [06:07<06:54,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 48% 48/100 [06:15<06:46,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 49% 49/100 [06:23<06:38,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 50% 50/100 [06:30<06:30,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 51% 51/100 [06:38<06:22,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 52% 52/100 [06:46<06:14,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 53% 53/100 [06:52<05:47,  7.38s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 54% 54/100 [07:00<05:45,  7.50s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 55% 55/100 [07:08<05:41,  7.60s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 56% 56/100 [07:16<05:37,  7.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 57% 57/100 [07:24<05:31,  7.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 58% 58/100 [07:32<05:24,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 59% 59/100 [07:39<05:18,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 60% 60/100 [07:47<05:11,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 61% 61/100 [07:55<05:03,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 62% 62/100 [08:03<04:56,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 63% 63/100 [08:11<04:48,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 64% 64/100 [08:18<04:40,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 65% 65/100 [08:26<04:32,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 66% 66/100 [08:34<04:25,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 67% 67/100 [08:42<04:17,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 68% 68/100 [08:50<04:10,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 69% 69/100 [08:57<04:02,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 70% 70/100 [09:05<03:54,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 71% 71/100 [09:13<03:47,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 72% 72/100 [09:21<03:39,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 73% 73/100 [09:29<03:31,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 74% 74/100 [09:34<03:04,  7.10s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 75% 75/100 [09:42<03:02,  7.31s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 76% 76/100 [09:50<02:59,  7.46s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 77% 77/100 [09:58<02:54,  7.57s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 78% 78/100 [10:05<02:48,  7.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 79% 79/100 [10:13<02:41,  7.69s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 80% 80/100 [10:21<02:34,  7.73s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 81% 81/100 [10:29<02:27,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 82% 82/100 [10:37<02:19,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 83% 83/100 [10:44<02:12,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 84% 84/100 [10:52<02:04,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 85% 85/100 [11:00<01:56,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 86% 86/100 [11:08<01:49,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 87% 87/100 [11:16<01:41,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 88% 88/100 [11:23<01:33,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 89% 89/100 [11:29<01:17,  7.04s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 90% 90/100 [11:37<01:12,  7.28s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 91% 91/100 [11:44<01:07,  7.45s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 92% 92/100 [11:52<01:00,  7.55s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 93% 93/100 [12:00<00:53,  7.62s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 94% 94/100 [12:08<00:46,  7.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 95% 95/100 [12:16<00:38,  7.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 96% 96/100 [12:23<00:30,  7.74s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 97% 97/100 [12:31<00:23,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 98% 98/100 [12:39<00:15,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 99% 99/100 [12:47<00:07,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "100% 100/100 [12:55<00:00,  7.75s/it]\n",
            "INFO:root:Running temp = 0.15\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:07<12:51,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:15<12:44,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:23<12:37,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:31<12:28,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:39<12:21,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:46<12:13,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:54<12:06,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:02<11:58,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:10<11:50,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:18<11:43,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:25<11:35,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:33<11:27,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:41<11:19,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:49<11:11,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [01:57<11:03,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:04<10:55,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:12<10:48,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:20<10:39,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:28<10:31,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:36<10:23,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:43<10:15,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [02:51<10:07,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [02:59<10:00,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:07<09:52,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 25% 25/100 [03:15<09:44,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 26% 26/100 [03:22<09:36,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 27% 27/100 [03:30<09:29,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 28% 28/100 [03:38<09:21,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 29% 29/100 [03:46<09:13,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 30% 30/100 [03:54<09:05,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 31% 31/100 [04:01<08:57,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 32% 32/100 [04:09<08:49,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 33% 33/100 [04:17<08:42,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 34% 34/100 [04:25<08:34,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 35% 35/100 [04:33<08:27,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 36% 36/100 [04:40<08:19,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 37% 37/100 [04:48<08:12,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 38% 38/100 [04:56<08:03,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 39% 39/100 [05:04<07:56,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 40% 40/100 [05:12<07:48,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 41% 41/100 [05:19<07:40,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 42% 42/100 [05:27<07:32,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 43% 43/100 [05:32<06:30,  6.85s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 44% 44/100 [05:40<06:39,  7.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 45% 45/100 [05:47<06:43,  7.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 46% 46/100 [05:55<06:43,  7.48s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 47% 47/100 [06:03<06:41,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 48% 48/100 [06:11<06:37,  7.64s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 49% 49/100 [06:19<06:31,  7.68s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 50% 50/100 [06:26<06:25,  7.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 51% 51/100 [06:34<06:19,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 52% 52/100 [06:42<06:12,  7.76s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 53% 53/100 [06:50<06:05,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 54% 54/100 [06:58<05:57,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 55% 55/100 [07:05<05:50,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 56% 56/100 [07:13<05:42,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 57% 57/100 [07:21<05:35,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 58% 58/100 [07:29<05:27,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 59% 59/100 [07:37<05:19,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 60% 60/100 [07:44<05:11,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 61% 61/100 [07:52<05:03,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 62% 62/100 [08:00<04:56,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 63% 63/100 [08:08<04:48,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 64% 64/100 [08:16<04:40,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 65% 65/100 [08:23<04:32,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 66% 66/100 [08:31<04:25,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 67% 67/100 [08:39<04:17,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 68% 68/100 [08:47<04:09,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 69% 69/100 [08:55<04:01,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 70% 70/100 [09:02<03:53,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 71% 71/100 [09:10<03:46,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 72% 72/100 [09:18<03:38,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 73% 73/100 [09:26<03:30,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 74% 74/100 [09:34<03:22,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 75% 75/100 [09:41<03:15,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 76% 76/100 [09:49<03:07,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 77% 77/100 [09:57<02:59,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 78% 78/100 [10:05<02:51,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 79% 79/100 [10:13<02:43,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 80% 80/100 [10:20<02:36,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 81% 81/100 [10:28<02:28,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 82% 82/100 [10:36<02:20,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 83% 83/100 [10:44<02:12,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 84% 84/100 [10:52<02:05,  7.83s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 85% 85/100 [10:58<01:50,  7.34s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 86% 86/100 [11:06<01:44,  7.49s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 87% 87/100 [11:14<01:38,  7.59s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 88% 88/100 [11:21<01:31,  7.65s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 89% 89/100 [11:29<01:24,  7.71s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 90% 90/100 [11:37<01:17,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 91% 91/100 [11:45<01:09,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 92% 92/100 [11:53<01:02,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 93% 93/100 [12:01<00:54,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 94% 94/100 [12:08<00:46,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 95% 95/100 [12:16<00:39,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 96% 96/100 [12:24<00:31,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 97% 97/100 [12:32<00:23,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 98% 98/100 [12:40<00:15,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 99% 99/100 [12:47<00:07,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "100% 100/100 [12:55<00:00,  7.76s/it]\n",
            "INFO:root:Running temp = 0.2\n",
            "  0% 0/100 [00:00<?, ?it/s]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  1% 1/100 [00:07<12:50,  7.78s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  2% 2/100 [00:14<11:40,  7.14s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  3% 3/100 [00:22<12:01,  7.44s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  4% 4/100 [00:30<12:08,  7.58s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  5% 5/100 [00:37<12:08,  7.67s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  6% 6/100 [00:45<12:05,  7.72s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  7% 7/100 [00:53<12:00,  7.75s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  8% 8/100 [01:01<11:54,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            "  9% 9/100 [01:09<11:47,  7.77s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 10% 10/100 [01:16<11:41,  7.79s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 11% 11/100 [01:24<11:34,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 12% 12/100 [01:32<11:26,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 13% 13/100 [01:40<11:19,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 14% 14/100 [01:48<11:11,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 15% 15/100 [01:55<11:03,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 16% 16/100 [02:03<10:55,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 17% 17/100 [02:11<10:48,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 18% 18/100 [02:19<10:39,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 19% 19/100 [02:27<10:32,  7.80s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 20% 20/100 [02:35<10:24,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 21% 21/100 [02:42<10:16,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 22% 22/100 [02:50<10:08,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 23% 23/100 [02:58<10:01,  7.82s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n",
            " 24% 24/100 [03:06<09:53,  7.81s/it]The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:11 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluate.py \\\n",
        "    --model falcon-7b \\\n",
        "    --evaluator_path /content/Jailbreak_LLM/evaluator \\\n",
        "    --scorer_path /content/Jailbreak_LLM/scorer/"
      ],
      "metadata": {
        "id": "ZVWAfiQMaOsp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}